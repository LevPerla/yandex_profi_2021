{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из-за сильнейшего ливня в лаборатории квантовой механики произошёл потоп, вследствие чего она была закрыта на срочный ремонт.  \n",
    "Однако учёные привыкли доводить все свои дела до конца, и ждать пока закончится ремонт были не намерены. Перед ними стояла задача определить критические температуры для сверхпроводников, созданных на основе различных химических элементов. Однако никаких привычных лабораторных приспособлений для этого не имелось, существовала только информация о характеристиках каждого из сверхпроводников и химические формулы сверхпроводников, которую им подсказали ученые-химики из соседней лаборатории. В поисках решения они решили изучить новейшие технологии в области анализа данных и обнаружили, что им может помочь машинное обучение. \n",
    "\n",
    "Помогите учёным-физикам, не имеющим опыта в решении задач машинного обучения, определить критические температуры всех сверхпроводников используя их характеристики и химический состав. \n",
    "\n",
    "Для обучения моделей необходимо воспользоваться информацией о сверхпроводниках, для которых ученые успели получить критическую температуру (train.csv). \n",
    "\n",
    "Возможно сделать предсказание более эффективным вам поможет химическая формула для каждого из сверхпроводников (formula_train.csv). \n",
    "Целевым полем является поле critical_temperature.  \n",
    "Ваша задача для недостающих соединений (test.csv) предсказать поле critical_temperature и в качестве ответа загрузить файл answer.csv, где будет одна колонка с предсказанием (без заголовка колонки)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "def metrics_eval(y_true, y_pred, res=True):\n",
    "    \"\"\"\n",
    "    Evaluate MAE, MSE, SMAPE, RMSE, MAPE metrics\n",
    "    :param y_true: np.array of true values\n",
    "    :param y_pred: np.array of predicted values\n",
    "    :param res: bool, printing results\n",
    "    :return: list of metrics\n",
    "    \"\"\"\n",
    "    # Mean absolute error (MAE)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    # Mean squared error (MSE)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "    # SMAPE is an alternative for MAPE when there are zeros in the testing data. It\n",
    "    # scales the absolute percentage by the sum of forecast and observed values\n",
    "    SMAPE = np.mean(np.abs((y_true - y_pred) / ((y_true + y_pred) / 2))) * 100\n",
    "\n",
    "    # Calculate the Root Mean Squared Error\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "    # Calculate the Mean Absolute Percentage Error\n",
    "    # y, predictions = check_array(y, predictions)\n",
    "    MAPE = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    \n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    if res:\n",
    "        print('Mean Absolute Error:', round(mae, 3))\n",
    "        print('Mean Squared Error:', round(mse, 3))\n",
    "        print('Root Mean Squared Error:', round(rmse, 3))\n",
    "        print('Mean absolute percentage error:', round(MAPE, 3))\n",
    "        print('Scaled Mean absolute percentage error:', round(SMAPE, 3))\n",
    "        print('r2_score:', round(r2, 3))\n",
    "\n",
    "    return mae, mse, rmse, MAPE, SMAPE, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "test_df = pd.read_csv(\"data/test.csv\")\n",
    "formula_train_df = pd.read_csv(\"data/formula_train.csv\")\n",
    "formula_test_df = pd.read_csv(\"data/formula_test.csv\")\n",
    "\n",
    "# Process columns names\n",
    "train_df.columns = train_df.columns.str.replace('\\s+', '_', regex=True)\n",
    "test_df.columns = test_df.columns.str.replace('\\s+', '_', regex=True)\n",
    "formula_train_df.columns = formula_train_df.columns.str.replace('\\s+', '_', regex=True)\n",
    "formula_test_df.columns = formula_test_df.columns.str.replace('\\s+', '_', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   feature1   feature2   feature3   feature4   feature5  feature6  feature7  \\\n0         4  95.950150  87.221940  89.534122  81.423258  1.317590  1.301059   \n1         5  83.244760  59.224400  59.506081  36.126175  1.311510  1.372050   \n2         2  23.035850  26.647510  21.192566  25.010514  0.614232  0.435817   \n3         4  81.756699  79.833804  76.282833  75.275775  1.312596  1.149324   \n4         2  67.485250  69.699016  57.442709  59.574464  0.548263  0.521345   \n\n   feature8   feature9  feature10  ...  feature73  feature74  feature75  \\\n0   96.1190  20.285800  36.105357  ...       4.10   4.053600   3.944244   \n1  192.9810  25.192187  67.233835  ...       2.40   2.402249   2.259897   \n2   18.0583  18.243490   9.029150  ...       5.10   4.242641   4.873514   \n3   81.4820  28.789976  32.890369  ...       3.62   3.309751   3.413039   \n4   70.8405  39.638078  35.420250  ...       6.00   6.000000   6.000000   \n\n   feature76  feature77  feature78  feature79  feature80  feature81  \\\n0   1.339718   1.245504          3   1.400000   1.299038   1.135782   \n1   1.519383   1.365077          3   0.933333   1.200000   1.019804   \n2   0.636514   0.465999          3   3.300000   1.500000   1.374773   \n3   1.333736   1.019322          3   1.920000   1.118034   1.198165   \n4   0.693147   0.691193          0   0.375000   0.000000   0.000000   \n\n   critical_temperature  \n0                 21.50  \n1                 62.00  \n2                  0.29  \n3                 19.50  \n4                  5.36  \n\n[5 rows x 82 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature1</th>\n      <th>feature2</th>\n      <th>feature3</th>\n      <th>feature4</th>\n      <th>feature5</th>\n      <th>feature6</th>\n      <th>feature7</th>\n      <th>feature8</th>\n      <th>feature9</th>\n      <th>feature10</th>\n      <th>...</th>\n      <th>feature73</th>\n      <th>feature74</th>\n      <th>feature75</th>\n      <th>feature76</th>\n      <th>feature77</th>\n      <th>feature78</th>\n      <th>feature79</th>\n      <th>feature80</th>\n      <th>feature81</th>\n      <th>critical_temperature</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>95.950150</td>\n      <td>87.221940</td>\n      <td>89.534122</td>\n      <td>81.423258</td>\n      <td>1.317590</td>\n      <td>1.301059</td>\n      <td>96.1190</td>\n      <td>20.285800</td>\n      <td>36.105357</td>\n      <td>...</td>\n      <td>4.10</td>\n      <td>4.053600</td>\n      <td>3.944244</td>\n      <td>1.339718</td>\n      <td>1.245504</td>\n      <td>3</td>\n      <td>1.400000</td>\n      <td>1.299038</td>\n      <td>1.135782</td>\n      <td>21.50</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>83.244760</td>\n      <td>59.224400</td>\n      <td>59.506081</td>\n      <td>36.126175</td>\n      <td>1.311510</td>\n      <td>1.372050</td>\n      <td>192.9810</td>\n      <td>25.192187</td>\n      <td>67.233835</td>\n      <td>...</td>\n      <td>2.40</td>\n      <td>2.402249</td>\n      <td>2.259897</td>\n      <td>1.519383</td>\n      <td>1.365077</td>\n      <td>3</td>\n      <td>0.933333</td>\n      <td>1.200000</td>\n      <td>1.019804</td>\n      <td>62.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>23.035850</td>\n      <td>26.647510</td>\n      <td>21.192566</td>\n      <td>25.010514</td>\n      <td>0.614232</td>\n      <td>0.435817</td>\n      <td>18.0583</td>\n      <td>18.243490</td>\n      <td>9.029150</td>\n      <td>...</td>\n      <td>5.10</td>\n      <td>4.242641</td>\n      <td>4.873514</td>\n      <td>0.636514</td>\n      <td>0.465999</td>\n      <td>3</td>\n      <td>3.300000</td>\n      <td>1.500000</td>\n      <td>1.374773</td>\n      <td>0.29</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>81.756699</td>\n      <td>79.833804</td>\n      <td>76.282833</td>\n      <td>75.275775</td>\n      <td>1.312596</td>\n      <td>1.149324</td>\n      <td>81.4820</td>\n      <td>28.789976</td>\n      <td>32.890369</td>\n      <td>...</td>\n      <td>3.62</td>\n      <td>3.309751</td>\n      <td>3.413039</td>\n      <td>1.333736</td>\n      <td>1.019322</td>\n      <td>3</td>\n      <td>1.920000</td>\n      <td>1.118034</td>\n      <td>1.198165</td>\n      <td>19.50</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>67.485250</td>\n      <td>69.699016</td>\n      <td>57.442709</td>\n      <td>59.574464</td>\n      <td>0.548263</td>\n      <td>0.521345</td>\n      <td>70.8405</td>\n      <td>39.638078</td>\n      <td>35.420250</td>\n      <td>...</td>\n      <td>6.00</td>\n      <td>6.000000</td>\n      <td>6.000000</td>\n      <td>0.693147</td>\n      <td>0.691193</td>\n      <td>0</td>\n      <td>0.375000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.36</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 82 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     H  He   Li   Be    B    C    N    O    F  Ne  ...   Pt   Au   Hg   Tl  \\\n0  0.0   0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0  ...  0.0  0.0  0.0  0.0   \n1  0.0   0  0.0  0.0  0.0  0.0  0.0  8.0  0.0   0  ...  0.0  0.0  0.0  0.0   \n2  0.0   0  0.0  0.0  0.0  0.0  0.3  0.0  0.0   0  ...  0.0  0.0  0.0  0.0   \n3  0.0   0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0  ...  0.0  0.0  0.0  0.0   \n4  0.0   0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0  ...  0.0  0.0  0.0  0.0   \n\n    Pb   Bi  Po  At  Rn          material  \n0  0.0  0.0   0   0   0  Eu1Fe1.5Ru0.5As2  \n1  0.0  2.0   0   0   0    Bi2Sr2Ca1Cu2O8  \n2  0.0  0.0   0   0   0          N0.3S0.7  \n3  0.0  0.0   0   0   0  Ba1Fe1.9Co0.1As2  \n4  0.0  0.0   0   0   0           Rh17S15  \n\n[5 rows x 87 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>H</th>\n      <th>He</th>\n      <th>Li</th>\n      <th>Be</th>\n      <th>B</th>\n      <th>C</th>\n      <th>N</th>\n      <th>O</th>\n      <th>F</th>\n      <th>Ne</th>\n      <th>...</th>\n      <th>Pt</th>\n      <th>Au</th>\n      <th>Hg</th>\n      <th>Tl</th>\n      <th>Pb</th>\n      <th>Bi</th>\n      <th>Po</th>\n      <th>At</th>\n      <th>Rn</th>\n      <th>material</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Eu1Fe1.5Ru0.5As2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Bi2Sr2Ca1Cu2O8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>N0.3S0.7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Ba1Fe1.9Co0.1As2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Rh17S15</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 87 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "target_col = \"critical_temperature\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train_df, formula_train_df], axis=1).drop(\"material\",axis=1)\n",
    "X = train.drop(target_col, axis=1)\n",
    "Y = train[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, Y,\n",
    "                                                  train_size=0.94,\n",
    "                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "my_scaler = MinMaxScaler()\n",
    "X_train = pd.DataFrame(my_scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_val = pd.DataFrame(my_scaler.transform(X_val), columns=X_val.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Linear regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Define function for residual analysis\n",
    "\n",
    "def resid_normality_analisis(residuals, alpha=0.05):\n",
    "    print(\"QQ-Plot of residuals\")\n",
    "    sm.qqplot(residuals, fit=True, line='45')\n",
    "    plt.show()\n",
    "\n",
    "    # resid distribution plot\n",
    "    pd.Series(residuals).plot(kind='kde', title=\"Plot of residual distribution\")\n",
    "    plt.show()\n",
    "\n",
    "    # Jarque-Bera Wald Test for Normality\n",
    "    jbtest = sm.stats.stattools.jarque_bera(residuals)\n",
    "    print('\\nJarque-Bera Wald Test for Normality')\n",
    "    print('Skewness of Residuals = ', jbtest[2])\n",
    "    print('Kurtosis of Residuals = ', jbtest[3])\n",
    "    df2 = pd.Series({'Chi-Sq( 2)': jbtest[0], 'Prob>Chi-Sq': jbtest[1]})\n",
    "    print(df2)\n",
    "    if jbtest[1] >= alpha:\n",
    "        print(\"Residuals have normal distribution\")\n",
    "    else:\n",
    "        print(\"Residuals have not normal distribution\")\n",
    "\n",
    "    print()\n",
    "    print(pd.Series(residuals).describe())\n",
    "\n",
    "def resid_het_analisis(X, y, alpha=0.05):\n",
    "    print(\"Goldfeld-Quandt test:\")\n",
    "    GQ_test = sm.stats.diagnostic.het_goldfeldquandt(y, X,\n",
    "                                                     idx=None,\n",
    "                                                     split=None,\n",
    "                                                     drop=None)\n",
    "    df2 = pd.Series({'F(14,14)': GQ_test[0], 'Prob>F': GQ_test[1]})\n",
    "    print(df2)\n",
    "\n",
    "    if GQ_test[1] >= alpha:\n",
    "        print(\"\\nGoldfeld-Quandt test: There isn't Heteroscedasticity in residuals\")\n",
    "    else:\n",
    "        print(\"\\nGoldfeld-Quandt test: There is Heteroscedasticity in residuals\")\n",
    "\n",
    "def resid_autocorr_analisis(residuals):\n",
    "    print(\"Durbin-Watson test for AR(1):\")\n",
    "    dw_statistic = sm.stats.durbin_watson(residuals)\n",
    "    print(f\"dw_statistic: {dw_statistic}\")\n",
    "    if (dw_statistic >= 1.5) and (dw_statistic <= 2.5):\n",
    "        print(\"1.5 <= dw_statistic <= 2.5\")\n",
    "        print(\"There isn't autocorrelation in residuals\")\n",
    "    elif (dw_statistic < 1.5):\n",
    "        print(\"dw_statistic < 1.5\")\n",
    "        print(\"There is autocorrelation in residuals\")\n",
    "    else:\n",
    "        print(\"2.5 < dw_statistic\")\n",
    "        print(\"There is autocorrelation in residuals\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                                 OLS Regression Results                                \n=======================================================================================\nDep. Variable:                      y   R-squared (uncentered):                   0.883\nModel:                            OLS   Adj. R-squared (uncentered):              0.882\nMethod:                 Least Squares   F-statistic:                              756.8\nDate:                Mon, 12 Dec 2022   Prob (F-statistic):                        0.00\nTime:                        13:16:40   Log-Likelihood:                         -67596.\nNo. Observations:               15980   AIC:                                  1.355e+05\nDf Residuals:                   15822   BIC:                                  1.367e+05\nDf Model:                         158                                                  \nCovariance Type:            nonrobust                                                  \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nfeature1      -0.6518      6.906     -0.094      0.925     -14.188      12.884\nfeature2     187.2261     19.019      9.844      0.000     149.948     224.505\nfeature3    -263.2368     24.056    -10.943      0.000    -310.388    -216.085\nfeature4     -94.9107     18.809     -5.046      0.000    -131.779     -58.043\nfeature5     158.9611     23.031      6.902      0.000     113.819     204.104\nfeature6     -39.0126     10.901     -3.579      0.000     -60.380     -17.645\nfeature7       4.2574      8.316      0.512      0.609     -12.043      20.558\nfeature8      37.8567      4.029      9.395      0.000      29.958      45.755\nfeature9      22.7923      5.106      4.464      0.000      12.784      32.801\nfeature10    -49.7595      7.357     -6.763      0.000     -64.181     -35.339\nfeature11      4.5516      6.407      0.710      0.477      -8.007      17.110\nfeature12   -161.0236     62.385     -2.581      0.010    -283.306     -38.741\nfeature13    -17.3746     76.374     -0.227      0.820    -167.077     132.328\nfeature14    135.6173     62.004      2.187      0.029      14.082     257.153\nfeature15     59.5562     74.063      0.804      0.421     -85.616     204.728\nfeature16    -63.8437     51.930     -1.229      0.219    -165.632      37.944\nfeature17    119.6511     11.717     10.212      0.000      96.685     142.617\nfeature18     66.2736      9.970      6.647      0.000      46.731      85.817\nfeature19     27.1235      5.125      5.292      0.000      17.077      37.170\nfeature20    -55.0385     13.215     -4.165      0.000     -80.941     -29.136\nfeature21     -7.7007     11.493     -0.670      0.503     -30.228      14.827\nfeature22   -166.2182     43.465     -3.824      0.000    -251.414     -81.023\nfeature23    476.8596     57.392      8.309      0.000     364.364     589.355\nfeature24    106.0124     43.752      2.423      0.015      20.254     191.771\nfeature25   -412.0718     56.009     -7.357      0.000    -521.856    -302.288\nfeature26    -19.4048     46.653     -0.416      0.677    -110.851      72.041\nfeature27     39.3972     11.761      3.350      0.001      16.344      62.451\nfeature28     16.9906      6.637      2.560      0.010       3.980      30.001\nfeature29    -16.1994      4.318     -3.752      0.000     -24.663      -7.735\nfeature30    -24.9747     12.947     -1.929      0.054     -50.351       0.402\nfeature31     -9.9587      9.239     -1.078      0.281     -28.068       8.151\nfeature32   -124.6903     13.692     -9.107      0.000    -151.528     -97.853\nfeature33    113.2136     16.906      6.697      0.000      80.075     146.352\nfeature34     17.7907     12.764      1.394      0.163      -7.229      42.810\nfeature35    -10.7802     15.570     -0.692      0.489     -41.299      19.738\nfeature36    -17.6260      8.761     -2.012      0.044     -34.799      -0.453\nfeature37      0.8592      5.418      0.159      0.874      -9.760      11.479\nfeature38    -22.5401      5.933     -3.799      0.000     -34.170     -10.911\nfeature39    -12.3618      6.575     -1.880      0.060     -25.250       0.526\nfeature40     34.2984      8.601      3.988      0.000      17.440      51.157\nfeature41     -9.6996      6.060     -1.601      0.110     -21.579       2.179\nfeature42    -16.4342     15.810     -1.039      0.299     -47.423      14.555\nfeature43    105.2211     17.784      5.917      0.000      70.362     140.080\nfeature44     36.1236     13.636      2.649      0.008       9.396      62.851\nfeature45   -127.5628     15.664     -8.144      0.000    -158.267     -96.859\nfeature46     15.7365      5.272      2.985      0.003       5.403      26.070\nfeature47    -30.0814      4.267     -7.050      0.000     -38.445     -21.718\nfeature48   -113.8610      7.605    -14.971      0.000    -128.768     -98.954\nfeature49    -16.5950      5.190     -3.198      0.001     -26.767      -6.423\nfeature50    183.6293     11.380     16.136      0.000     161.323     205.935\nfeature51    -82.4586      7.901    -10.436      0.000     -97.946     -66.972\nfeature52    111.7374     23.822      4.691      0.000      65.045     158.430\nfeature53   -179.7621     24.854     -7.233      0.000    -228.480    -131.045\nfeature54    -76.4167     22.665     -3.372      0.001    -120.843     -31.990\nfeature55    131.1188     23.819      5.505      0.000      84.432     177.806\nfeature56    -40.7040      6.910     -5.890      0.000     -54.249     -27.159\nfeature57     41.3601      4.083     10.131      0.000      33.358      49.362\nfeature58    -22.9863      8.260     -2.783      0.005     -39.177      -6.795\nfeature59     59.0804      7.797      7.577      0.000      43.797      74.364\nfeature60    -30.3256     15.776     -1.922      0.055     -61.249       0.598\nfeature61     35.1247      9.622      3.651      0.000      16.265      53.985\nfeature62    -24.8944      9.535     -2.611      0.009     -43.584      -6.205\nfeature63    204.8948     13.555     15.116      0.000     178.326     231.464\nfeature64    -18.4893      8.727     -2.119      0.034     -35.594      -1.384\nfeature65   -124.7467     11.924    -10.462      0.000    -148.120    -101.374\nfeature66     21.6667      3.805      5.694      0.000      14.208      29.125\nfeature67      0.9715      3.030      0.321      0.748      -4.967       6.910\nfeature68    -49.8613      6.693     -7.450      0.000     -62.980     -36.742\nfeature69    -82.6985      7.512    -11.008      0.000     -97.424     -67.973\nfeature70     75.2610     10.290      7.314      0.000      55.092      95.430\nfeature71      2.2780      5.806      0.392      0.695      -9.103      13.659\nfeature72     75.1883     41.944      1.793      0.073      -7.027     157.403\nfeature73   -112.8714     51.289     -2.201      0.028    -213.403     -12.339\nfeature74    -46.9008     39.526     -1.187      0.235    -124.376      30.574\nfeature75     90.2921     48.042      1.879      0.060      -3.875     184.460\nfeature76    140.1981     31.616      4.434      0.000      78.228     202.169\nfeature77   -151.7724     12.739    -11.914      0.000    -176.742    -126.803\nfeature78     39.1685      4.920      7.961      0.000      29.524      48.813\nfeature79    -17.5998      5.046     -3.488      0.000     -27.490      -7.709\nfeature80    -14.1264      8.574     -1.648      0.099     -30.933       2.680\nfeature81    -46.0929      6.948     -6.634      0.000     -59.712     -32.473\nH             -2.5374      9.776     -0.260      0.795     -21.700      16.625\nHe          9.811e-13   1.57e-13      6.252      0.000    6.74e-13    1.29e-12\nLi             8.6794      3.466      2.504      0.012       1.887      15.472\nBe           -16.2793      7.080     -2.299      0.021     -30.157      -2.402\nB            -30.5082     14.801     -2.061      0.039     -59.521      -1.496\nC            -10.9841      8.646     -1.270      0.204     -27.931       5.963\nN             -2.6712     13.059     -0.205      0.838     -28.268      22.926\nO            -25.5622      8.012     -3.190      0.001     -41.267      -9.858\nF             34.0580      5.694      5.982      0.000      22.898      45.218\nNe          -9.84e-15   9.39e-14     -0.105      0.917   -1.94e-13    1.74e-13\nNa            29.0203      6.713      4.323      0.000      15.862      42.179\nMg             2.4707      8.266      0.299      0.765     -13.731      18.673\nAl           -15.7600      7.846     -2.009      0.045     -31.139      -0.381\nSi          -159.4481      8.977    -17.761      0.000    -177.045    -141.852\nP            -35.3342      7.342     -4.813      0.000     -49.725     -20.944\nS            -27.9400      3.928     -7.114      0.000     -35.639     -20.241\nCl           -16.2877      5.530     -2.946      0.003     -27.126      -5.449\nAr         -1.506e-13   1.41e-13     -1.067      0.286   -4.27e-13    1.26e-13\nK             32.0847      4.922      6.519      0.000      22.438      41.732\nCa            36.8217      8.042      4.579      0.000      21.059      52.584\nSc             1.2114      3.989      0.304      0.761      -6.608       9.031\nTi            -5.2852      4.184     -1.263      0.206     -13.485       2.915\nV              5.1497      3.644      1.413      0.158      -1.993      12.293\nCr             3.0989      7.637      0.406      0.685     -11.871      18.068\nMn            -8.1620     14.526     -0.562      0.574     -36.635      20.311\nFe            36.3291     11.305      3.214      0.001      14.171      58.488\nCo           -19.3497      9.336     -2.072      0.038     -37.650      -1.049\nNi           -13.7398      7.001     -1.963      0.050     -27.462      -0.018\nCu           -53.7812     10.273     -5.235      0.000     -73.917     -33.645\nZn            -3.9829      6.564     -0.607      0.544     -16.848       8.882\nGa            11.4373      6.309      1.813      0.070      -0.929      23.804\nGe           -48.6390      7.236     -6.721      0.000     -62.823     -34.455\nAs           -34.2180      5.456     -6.272      0.000     -44.912     -23.524\nSe           -21.5930      4.909     -4.398      0.000     -31.216     -11.970\nBr             6.2667      8.524      0.735      0.462     -10.442      22.975\nKr          2.941e-13   4.94e-14      5.954      0.000    1.97e-13    3.91e-13\nRb            46.1221      6.515      7.080      0.000      33.352      58.892\nSr             3.7730      6.710      0.562      0.574      -9.380      16.926\nY             -7.4588      4.052     -1.841      0.066     -15.402       0.484\nZr            -0.2442      3.554     -0.069      0.945      -7.211       6.722\nNb            10.5669      3.536      2.988      0.003       3.636      17.498\nMo            14.1377      6.704      2.109      0.035       0.998      27.278\nTc            12.5309     11.727      1.069      0.285     -10.456      35.518\nRu            18.3611     12.695      1.446      0.148      -6.523      43.246\nRh            -3.4425      7.248     -0.475      0.635     -17.650      10.765\nPd            -0.3406      7.375     -0.046      0.963     -14.797      14.116\nAg           -83.2954      6.070    -13.722      0.000     -95.193     -71.398\nCd           -16.9699     16.972     -1.000      0.317     -50.238      16.298\nIn            17.6943      4.597      3.849      0.000       8.684      26.704\nSn           -11.6178      8.600     -1.351      0.177     -28.474       5.239\nSb            -2.7372     11.593     -0.236      0.813     -25.461      19.987\nTe            10.6440     12.424      0.857      0.392     -13.709      34.997\nI             19.1447      5.163      3.708      0.000       9.024      29.266\nXe         -1.127e-13   1.53e-14     -7.384      0.000   -1.43e-13   -8.28e-14\nCs            25.0755      6.785      3.696      0.000      11.776      38.375\nBa           206.5906      8.729     23.668      0.000     189.482     223.700\nLa             2.4808      6.184      0.401      0.688      -9.640      14.602\nCe           -14.2476      4.610     -3.091      0.002     -23.283      -5.212\nPr            -5.0502     17.160     -0.294      0.769     -38.686      28.586\nNd            -9.5486      3.949     -2.418      0.016     -17.288      -1.809\nPm         -3.345e-14   6.11e-15     -5.473      0.000   -4.54e-14   -2.15e-14\nSm           -16.7340      5.206     -3.214      0.001     -26.938      -6.530\nEu           -12.0473      5.592     -2.154      0.031     -23.008      -1.087\nGd            -2.6984      3.748     -0.720      0.472     -10.045       4.648\nTb            -5.1707      7.606     -0.680      0.497     -20.080       9.738\nDy            17.9117      6.370      2.812      0.005       5.426      30.398\nHo            15.7614      6.698      2.353      0.019       2.632      28.890\nEr            11.8549      5.263      2.253      0.024       1.540      22.170\nTm             5.9715      5.436      1.099      0.272      -4.683      16.626\nYb            48.4911     11.915      4.070      0.000      25.137      71.845\nLu            27.5575      3.838      7.180      0.000      20.035      35.080\nHf           -14.7490     14.629     -1.008      0.313     -43.423      13.925\nTa            -2.4419     11.430     -0.214      0.831     -24.846      19.962\nW              0.7214      7.127      0.101      0.919     -13.248      14.691\nRe            -6.3622     10.415     -0.611      0.541     -26.778      14.053\nOs             6.0439      5.071      1.192      0.233      -3.896      15.984\nIr             3.0530      8.998      0.339      0.734     -14.584      20.690\nPt            22.0821      3.289      6.715      0.000      15.636      28.528\nAu           -43.6501     15.333     -2.847      0.004     -73.704     -13.596\nHg            40.4470      7.291      5.548      0.000      26.156      54.738\nTl            23.4660      3.160      7.426      0.000      17.272      29.660\nPb            24.4639     10.411      2.350      0.019       4.057      44.871\nBi            92.0024      5.392     17.063      0.000      81.434     102.571\nPo                  0          0        nan        nan           0           0\nAt                  0          0        nan        nan           0           0\nRn                  0          0        nan        nan           0           0\n==============================================================================\nOmnibus:                     1317.904   Durbin-Watson:                   1.965\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             3671.459\nSkew:                          -0.459   Prob(JB):                         0.00\nKurtosis:                       5.162   Cond. No.                     1.04e+16\n==============================================================================\n\nNotes:\n[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[3] The smallest eigenvalue is 1.83e-27. This might indicate that there are\nstrong multicollinearity problems or that the design matrix is singular.\n\"\"\"",
      "text/html": "<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.883</td> \n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.882</td> \n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   756.8</td> \n</tr>\n<tr>\n  <th>Date:</th>             <td>Mon, 12 Dec 2022</td> <th>  Prob (F-statistic):</th>           <td>  0.00</td>  \n</tr>\n<tr>\n  <th>Time:</th>                 <td>13:16:40</td>     <th>  Log-Likelihood:    </th>          <td> -67596.</td> \n</tr>\n<tr>\n  <th>No. Observations:</th>      <td> 15980</td>      <th>  AIC:               </th>          <td>1.355e+05</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td> 15822</td>      <th>  BIC:               </th>          <td>1.367e+05</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>   158</td>      <th>                     </th>              <td> </td>    \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>feature1</th>  <td>   -0.6518</td> <td>    6.906</td> <td>   -0.094</td> <td> 0.925</td> <td>  -14.188</td> <td>   12.884</td>\n</tr>\n<tr>\n  <th>feature2</th>  <td>  187.2261</td> <td>   19.019</td> <td>    9.844</td> <td> 0.000</td> <td>  149.948</td> <td>  224.505</td>\n</tr>\n<tr>\n  <th>feature3</th>  <td> -263.2368</td> <td>   24.056</td> <td>  -10.943</td> <td> 0.000</td> <td> -310.388</td> <td> -216.085</td>\n</tr>\n<tr>\n  <th>feature4</th>  <td>  -94.9107</td> <td>   18.809</td> <td>   -5.046</td> <td> 0.000</td> <td> -131.779</td> <td>  -58.043</td>\n</tr>\n<tr>\n  <th>feature5</th>  <td>  158.9611</td> <td>   23.031</td> <td>    6.902</td> <td> 0.000</td> <td>  113.819</td> <td>  204.104</td>\n</tr>\n<tr>\n  <th>feature6</th>  <td>  -39.0126</td> <td>   10.901</td> <td>   -3.579</td> <td> 0.000</td> <td>  -60.380</td> <td>  -17.645</td>\n</tr>\n<tr>\n  <th>feature7</th>  <td>    4.2574</td> <td>    8.316</td> <td>    0.512</td> <td> 0.609</td> <td>  -12.043</td> <td>   20.558</td>\n</tr>\n<tr>\n  <th>feature8</th>  <td>   37.8567</td> <td>    4.029</td> <td>    9.395</td> <td> 0.000</td> <td>   29.958</td> <td>   45.755</td>\n</tr>\n<tr>\n  <th>feature9</th>  <td>   22.7923</td> <td>    5.106</td> <td>    4.464</td> <td> 0.000</td> <td>   12.784</td> <td>   32.801</td>\n</tr>\n<tr>\n  <th>feature10</th> <td>  -49.7595</td> <td>    7.357</td> <td>   -6.763</td> <td> 0.000</td> <td>  -64.181</td> <td>  -35.339</td>\n</tr>\n<tr>\n  <th>feature11</th> <td>    4.5516</td> <td>    6.407</td> <td>    0.710</td> <td> 0.477</td> <td>   -8.007</td> <td>   17.110</td>\n</tr>\n<tr>\n  <th>feature12</th> <td> -161.0236</td> <td>   62.385</td> <td>   -2.581</td> <td> 0.010</td> <td> -283.306</td> <td>  -38.741</td>\n</tr>\n<tr>\n  <th>feature13</th> <td>  -17.3746</td> <td>   76.374</td> <td>   -0.227</td> <td> 0.820</td> <td> -167.077</td> <td>  132.328</td>\n</tr>\n<tr>\n  <th>feature14</th> <td>  135.6173</td> <td>   62.004</td> <td>    2.187</td> <td> 0.029</td> <td>   14.082</td> <td>  257.153</td>\n</tr>\n<tr>\n  <th>feature15</th> <td>   59.5562</td> <td>   74.063</td> <td>    0.804</td> <td> 0.421</td> <td>  -85.616</td> <td>  204.728</td>\n</tr>\n<tr>\n  <th>feature16</th> <td>  -63.8437</td> <td>   51.930</td> <td>   -1.229</td> <td> 0.219</td> <td> -165.632</td> <td>   37.944</td>\n</tr>\n<tr>\n  <th>feature17</th> <td>  119.6511</td> <td>   11.717</td> <td>   10.212</td> <td> 0.000</td> <td>   96.685</td> <td>  142.617</td>\n</tr>\n<tr>\n  <th>feature18</th> <td>   66.2736</td> <td>    9.970</td> <td>    6.647</td> <td> 0.000</td> <td>   46.731</td> <td>   85.817</td>\n</tr>\n<tr>\n  <th>feature19</th> <td>   27.1235</td> <td>    5.125</td> <td>    5.292</td> <td> 0.000</td> <td>   17.077</td> <td>   37.170</td>\n</tr>\n<tr>\n  <th>feature20</th> <td>  -55.0385</td> <td>   13.215</td> <td>   -4.165</td> <td> 0.000</td> <td>  -80.941</td> <td>  -29.136</td>\n</tr>\n<tr>\n  <th>feature21</th> <td>   -7.7007</td> <td>   11.493</td> <td>   -0.670</td> <td> 0.503</td> <td>  -30.228</td> <td>   14.827</td>\n</tr>\n<tr>\n  <th>feature22</th> <td> -166.2182</td> <td>   43.465</td> <td>   -3.824</td> <td> 0.000</td> <td> -251.414</td> <td>  -81.023</td>\n</tr>\n<tr>\n  <th>feature23</th> <td>  476.8596</td> <td>   57.392</td> <td>    8.309</td> <td> 0.000</td> <td>  364.364</td> <td>  589.355</td>\n</tr>\n<tr>\n  <th>feature24</th> <td>  106.0124</td> <td>   43.752</td> <td>    2.423</td> <td> 0.015</td> <td>   20.254</td> <td>  191.771</td>\n</tr>\n<tr>\n  <th>feature25</th> <td> -412.0718</td> <td>   56.009</td> <td>   -7.357</td> <td> 0.000</td> <td> -521.856</td> <td> -302.288</td>\n</tr>\n<tr>\n  <th>feature26</th> <td>  -19.4048</td> <td>   46.653</td> <td>   -0.416</td> <td> 0.677</td> <td> -110.851</td> <td>   72.041</td>\n</tr>\n<tr>\n  <th>feature27</th> <td>   39.3972</td> <td>   11.761</td> <td>    3.350</td> <td> 0.001</td> <td>   16.344</td> <td>   62.451</td>\n</tr>\n<tr>\n  <th>feature28</th> <td>   16.9906</td> <td>    6.637</td> <td>    2.560</td> <td> 0.010</td> <td>    3.980</td> <td>   30.001</td>\n</tr>\n<tr>\n  <th>feature29</th> <td>  -16.1994</td> <td>    4.318</td> <td>   -3.752</td> <td> 0.000</td> <td>  -24.663</td> <td>   -7.735</td>\n</tr>\n<tr>\n  <th>feature30</th> <td>  -24.9747</td> <td>   12.947</td> <td>   -1.929</td> <td> 0.054</td> <td>  -50.351</td> <td>    0.402</td>\n</tr>\n<tr>\n  <th>feature31</th> <td>   -9.9587</td> <td>    9.239</td> <td>   -1.078</td> <td> 0.281</td> <td>  -28.068</td> <td>    8.151</td>\n</tr>\n<tr>\n  <th>feature32</th> <td> -124.6903</td> <td>   13.692</td> <td>   -9.107</td> <td> 0.000</td> <td> -151.528</td> <td>  -97.853</td>\n</tr>\n<tr>\n  <th>feature33</th> <td>  113.2136</td> <td>   16.906</td> <td>    6.697</td> <td> 0.000</td> <td>   80.075</td> <td>  146.352</td>\n</tr>\n<tr>\n  <th>feature34</th> <td>   17.7907</td> <td>   12.764</td> <td>    1.394</td> <td> 0.163</td> <td>   -7.229</td> <td>   42.810</td>\n</tr>\n<tr>\n  <th>feature35</th> <td>  -10.7802</td> <td>   15.570</td> <td>   -0.692</td> <td> 0.489</td> <td>  -41.299</td> <td>   19.738</td>\n</tr>\n<tr>\n  <th>feature36</th> <td>  -17.6260</td> <td>    8.761</td> <td>   -2.012</td> <td> 0.044</td> <td>  -34.799</td> <td>   -0.453</td>\n</tr>\n<tr>\n  <th>feature37</th> <td>    0.8592</td> <td>    5.418</td> <td>    0.159</td> <td> 0.874</td> <td>   -9.760</td> <td>   11.479</td>\n</tr>\n<tr>\n  <th>feature38</th> <td>  -22.5401</td> <td>    5.933</td> <td>   -3.799</td> <td> 0.000</td> <td>  -34.170</td> <td>  -10.911</td>\n</tr>\n<tr>\n  <th>feature39</th> <td>  -12.3618</td> <td>    6.575</td> <td>   -1.880</td> <td> 0.060</td> <td>  -25.250</td> <td>    0.526</td>\n</tr>\n<tr>\n  <th>feature40</th> <td>   34.2984</td> <td>    8.601</td> <td>    3.988</td> <td> 0.000</td> <td>   17.440</td> <td>   51.157</td>\n</tr>\n<tr>\n  <th>feature41</th> <td>   -9.6996</td> <td>    6.060</td> <td>   -1.601</td> <td> 0.110</td> <td>  -21.579</td> <td>    2.179</td>\n</tr>\n<tr>\n  <th>feature42</th> <td>  -16.4342</td> <td>   15.810</td> <td>   -1.039</td> <td> 0.299</td> <td>  -47.423</td> <td>   14.555</td>\n</tr>\n<tr>\n  <th>feature43</th> <td>  105.2211</td> <td>   17.784</td> <td>    5.917</td> <td> 0.000</td> <td>   70.362</td> <td>  140.080</td>\n</tr>\n<tr>\n  <th>feature44</th> <td>   36.1236</td> <td>   13.636</td> <td>    2.649</td> <td> 0.008</td> <td>    9.396</td> <td>   62.851</td>\n</tr>\n<tr>\n  <th>feature45</th> <td> -127.5628</td> <td>   15.664</td> <td>   -8.144</td> <td> 0.000</td> <td> -158.267</td> <td>  -96.859</td>\n</tr>\n<tr>\n  <th>feature46</th> <td>   15.7365</td> <td>    5.272</td> <td>    2.985</td> <td> 0.003</td> <td>    5.403</td> <td>   26.070</td>\n</tr>\n<tr>\n  <th>feature47</th> <td>  -30.0814</td> <td>    4.267</td> <td>   -7.050</td> <td> 0.000</td> <td>  -38.445</td> <td>  -21.718</td>\n</tr>\n<tr>\n  <th>feature48</th> <td> -113.8610</td> <td>    7.605</td> <td>  -14.971</td> <td> 0.000</td> <td> -128.768</td> <td>  -98.954</td>\n</tr>\n<tr>\n  <th>feature49</th> <td>  -16.5950</td> <td>    5.190</td> <td>   -3.198</td> <td> 0.001</td> <td>  -26.767</td> <td>   -6.423</td>\n</tr>\n<tr>\n  <th>feature50</th> <td>  183.6293</td> <td>   11.380</td> <td>   16.136</td> <td> 0.000</td> <td>  161.323</td> <td>  205.935</td>\n</tr>\n<tr>\n  <th>feature51</th> <td>  -82.4586</td> <td>    7.901</td> <td>  -10.436</td> <td> 0.000</td> <td>  -97.946</td> <td>  -66.972</td>\n</tr>\n<tr>\n  <th>feature52</th> <td>  111.7374</td> <td>   23.822</td> <td>    4.691</td> <td> 0.000</td> <td>   65.045</td> <td>  158.430</td>\n</tr>\n<tr>\n  <th>feature53</th> <td> -179.7621</td> <td>   24.854</td> <td>   -7.233</td> <td> 0.000</td> <td> -228.480</td> <td> -131.045</td>\n</tr>\n<tr>\n  <th>feature54</th> <td>  -76.4167</td> <td>   22.665</td> <td>   -3.372</td> <td> 0.001</td> <td> -120.843</td> <td>  -31.990</td>\n</tr>\n<tr>\n  <th>feature55</th> <td>  131.1188</td> <td>   23.819</td> <td>    5.505</td> <td> 0.000</td> <td>   84.432</td> <td>  177.806</td>\n</tr>\n<tr>\n  <th>feature56</th> <td>  -40.7040</td> <td>    6.910</td> <td>   -5.890</td> <td> 0.000</td> <td>  -54.249</td> <td>  -27.159</td>\n</tr>\n<tr>\n  <th>feature57</th> <td>   41.3601</td> <td>    4.083</td> <td>   10.131</td> <td> 0.000</td> <td>   33.358</td> <td>   49.362</td>\n</tr>\n<tr>\n  <th>feature58</th> <td>  -22.9863</td> <td>    8.260</td> <td>   -2.783</td> <td> 0.005</td> <td>  -39.177</td> <td>   -6.795</td>\n</tr>\n<tr>\n  <th>feature59</th> <td>   59.0804</td> <td>    7.797</td> <td>    7.577</td> <td> 0.000</td> <td>   43.797</td> <td>   74.364</td>\n</tr>\n<tr>\n  <th>feature60</th> <td>  -30.3256</td> <td>   15.776</td> <td>   -1.922</td> <td> 0.055</td> <td>  -61.249</td> <td>    0.598</td>\n</tr>\n<tr>\n  <th>feature61</th> <td>   35.1247</td> <td>    9.622</td> <td>    3.651</td> <td> 0.000</td> <td>   16.265</td> <td>   53.985</td>\n</tr>\n<tr>\n  <th>feature62</th> <td>  -24.8944</td> <td>    9.535</td> <td>   -2.611</td> <td> 0.009</td> <td>  -43.584</td> <td>   -6.205</td>\n</tr>\n<tr>\n  <th>feature63</th> <td>  204.8948</td> <td>   13.555</td> <td>   15.116</td> <td> 0.000</td> <td>  178.326</td> <td>  231.464</td>\n</tr>\n<tr>\n  <th>feature64</th> <td>  -18.4893</td> <td>    8.727</td> <td>   -2.119</td> <td> 0.034</td> <td>  -35.594</td> <td>   -1.384</td>\n</tr>\n<tr>\n  <th>feature65</th> <td> -124.7467</td> <td>   11.924</td> <td>  -10.462</td> <td> 0.000</td> <td> -148.120</td> <td> -101.374</td>\n</tr>\n<tr>\n  <th>feature66</th> <td>   21.6667</td> <td>    3.805</td> <td>    5.694</td> <td> 0.000</td> <td>   14.208</td> <td>   29.125</td>\n</tr>\n<tr>\n  <th>feature67</th> <td>    0.9715</td> <td>    3.030</td> <td>    0.321</td> <td> 0.748</td> <td>   -4.967</td> <td>    6.910</td>\n</tr>\n<tr>\n  <th>feature68</th> <td>  -49.8613</td> <td>    6.693</td> <td>   -7.450</td> <td> 0.000</td> <td>  -62.980</td> <td>  -36.742</td>\n</tr>\n<tr>\n  <th>feature69</th> <td>  -82.6985</td> <td>    7.512</td> <td>  -11.008</td> <td> 0.000</td> <td>  -97.424</td> <td>  -67.973</td>\n</tr>\n<tr>\n  <th>feature70</th> <td>   75.2610</td> <td>   10.290</td> <td>    7.314</td> <td> 0.000</td> <td>   55.092</td> <td>   95.430</td>\n</tr>\n<tr>\n  <th>feature71</th> <td>    2.2780</td> <td>    5.806</td> <td>    0.392</td> <td> 0.695</td> <td>   -9.103</td> <td>   13.659</td>\n</tr>\n<tr>\n  <th>feature72</th> <td>   75.1883</td> <td>   41.944</td> <td>    1.793</td> <td> 0.073</td> <td>   -7.027</td> <td>  157.403</td>\n</tr>\n<tr>\n  <th>feature73</th> <td> -112.8714</td> <td>   51.289</td> <td>   -2.201</td> <td> 0.028</td> <td> -213.403</td> <td>  -12.339</td>\n</tr>\n<tr>\n  <th>feature74</th> <td>  -46.9008</td> <td>   39.526</td> <td>   -1.187</td> <td> 0.235</td> <td> -124.376</td> <td>   30.574</td>\n</tr>\n<tr>\n  <th>feature75</th> <td>   90.2921</td> <td>   48.042</td> <td>    1.879</td> <td> 0.060</td> <td>   -3.875</td> <td>  184.460</td>\n</tr>\n<tr>\n  <th>feature76</th> <td>  140.1981</td> <td>   31.616</td> <td>    4.434</td> <td> 0.000</td> <td>   78.228</td> <td>  202.169</td>\n</tr>\n<tr>\n  <th>feature77</th> <td> -151.7724</td> <td>   12.739</td> <td>  -11.914</td> <td> 0.000</td> <td> -176.742</td> <td> -126.803</td>\n</tr>\n<tr>\n  <th>feature78</th> <td>   39.1685</td> <td>    4.920</td> <td>    7.961</td> <td> 0.000</td> <td>   29.524</td> <td>   48.813</td>\n</tr>\n<tr>\n  <th>feature79</th> <td>  -17.5998</td> <td>    5.046</td> <td>   -3.488</td> <td> 0.000</td> <td>  -27.490</td> <td>   -7.709</td>\n</tr>\n<tr>\n  <th>feature80</th> <td>  -14.1264</td> <td>    8.574</td> <td>   -1.648</td> <td> 0.099</td> <td>  -30.933</td> <td>    2.680</td>\n</tr>\n<tr>\n  <th>feature81</th> <td>  -46.0929</td> <td>    6.948</td> <td>   -6.634</td> <td> 0.000</td> <td>  -59.712</td> <td>  -32.473</td>\n</tr>\n<tr>\n  <th>H</th>         <td>   -2.5374</td> <td>    9.776</td> <td>   -0.260</td> <td> 0.795</td> <td>  -21.700</td> <td>   16.625</td>\n</tr>\n<tr>\n  <th>He</th>        <td> 9.811e-13</td> <td> 1.57e-13</td> <td>    6.252</td> <td> 0.000</td> <td> 6.74e-13</td> <td> 1.29e-12</td>\n</tr>\n<tr>\n  <th>Li</th>        <td>    8.6794</td> <td>    3.466</td> <td>    2.504</td> <td> 0.012</td> <td>    1.887</td> <td>   15.472</td>\n</tr>\n<tr>\n  <th>Be</th>        <td>  -16.2793</td> <td>    7.080</td> <td>   -2.299</td> <td> 0.021</td> <td>  -30.157</td> <td>   -2.402</td>\n</tr>\n<tr>\n  <th>B</th>         <td>  -30.5082</td> <td>   14.801</td> <td>   -2.061</td> <td> 0.039</td> <td>  -59.521</td> <td>   -1.496</td>\n</tr>\n<tr>\n  <th>C</th>         <td>  -10.9841</td> <td>    8.646</td> <td>   -1.270</td> <td> 0.204</td> <td>  -27.931</td> <td>    5.963</td>\n</tr>\n<tr>\n  <th>N</th>         <td>   -2.6712</td> <td>   13.059</td> <td>   -0.205</td> <td> 0.838</td> <td>  -28.268</td> <td>   22.926</td>\n</tr>\n<tr>\n  <th>O</th>         <td>  -25.5622</td> <td>    8.012</td> <td>   -3.190</td> <td> 0.001</td> <td>  -41.267</td> <td>   -9.858</td>\n</tr>\n<tr>\n  <th>F</th>         <td>   34.0580</td> <td>    5.694</td> <td>    5.982</td> <td> 0.000</td> <td>   22.898</td> <td>   45.218</td>\n</tr>\n<tr>\n  <th>Ne</th>        <td> -9.84e-15</td> <td> 9.39e-14</td> <td>   -0.105</td> <td> 0.917</td> <td>-1.94e-13</td> <td> 1.74e-13</td>\n</tr>\n<tr>\n  <th>Na</th>        <td>   29.0203</td> <td>    6.713</td> <td>    4.323</td> <td> 0.000</td> <td>   15.862</td> <td>   42.179</td>\n</tr>\n<tr>\n  <th>Mg</th>        <td>    2.4707</td> <td>    8.266</td> <td>    0.299</td> <td> 0.765</td> <td>  -13.731</td> <td>   18.673</td>\n</tr>\n<tr>\n  <th>Al</th>        <td>  -15.7600</td> <td>    7.846</td> <td>   -2.009</td> <td> 0.045</td> <td>  -31.139</td> <td>   -0.381</td>\n</tr>\n<tr>\n  <th>Si</th>        <td> -159.4481</td> <td>    8.977</td> <td>  -17.761</td> <td> 0.000</td> <td> -177.045</td> <td> -141.852</td>\n</tr>\n<tr>\n  <th>P</th>         <td>  -35.3342</td> <td>    7.342</td> <td>   -4.813</td> <td> 0.000</td> <td>  -49.725</td> <td>  -20.944</td>\n</tr>\n<tr>\n  <th>S</th>         <td>  -27.9400</td> <td>    3.928</td> <td>   -7.114</td> <td> 0.000</td> <td>  -35.639</td> <td>  -20.241</td>\n</tr>\n<tr>\n  <th>Cl</th>        <td>  -16.2877</td> <td>    5.530</td> <td>   -2.946</td> <td> 0.003</td> <td>  -27.126</td> <td>   -5.449</td>\n</tr>\n<tr>\n  <th>Ar</th>        <td>-1.506e-13</td> <td> 1.41e-13</td> <td>   -1.067</td> <td> 0.286</td> <td>-4.27e-13</td> <td> 1.26e-13</td>\n</tr>\n<tr>\n  <th>K</th>         <td>   32.0847</td> <td>    4.922</td> <td>    6.519</td> <td> 0.000</td> <td>   22.438</td> <td>   41.732</td>\n</tr>\n<tr>\n  <th>Ca</th>        <td>   36.8217</td> <td>    8.042</td> <td>    4.579</td> <td> 0.000</td> <td>   21.059</td> <td>   52.584</td>\n</tr>\n<tr>\n  <th>Sc</th>        <td>    1.2114</td> <td>    3.989</td> <td>    0.304</td> <td> 0.761</td> <td>   -6.608</td> <td>    9.031</td>\n</tr>\n<tr>\n  <th>Ti</th>        <td>   -5.2852</td> <td>    4.184</td> <td>   -1.263</td> <td> 0.206</td> <td>  -13.485</td> <td>    2.915</td>\n</tr>\n<tr>\n  <th>V</th>         <td>    5.1497</td> <td>    3.644</td> <td>    1.413</td> <td> 0.158</td> <td>   -1.993</td> <td>   12.293</td>\n</tr>\n<tr>\n  <th>Cr</th>        <td>    3.0989</td> <td>    7.637</td> <td>    0.406</td> <td> 0.685</td> <td>  -11.871</td> <td>   18.068</td>\n</tr>\n<tr>\n  <th>Mn</th>        <td>   -8.1620</td> <td>   14.526</td> <td>   -0.562</td> <td> 0.574</td> <td>  -36.635</td> <td>   20.311</td>\n</tr>\n<tr>\n  <th>Fe</th>        <td>   36.3291</td> <td>   11.305</td> <td>    3.214</td> <td> 0.001</td> <td>   14.171</td> <td>   58.488</td>\n</tr>\n<tr>\n  <th>Co</th>        <td>  -19.3497</td> <td>    9.336</td> <td>   -2.072</td> <td> 0.038</td> <td>  -37.650</td> <td>   -1.049</td>\n</tr>\n<tr>\n  <th>Ni</th>        <td>  -13.7398</td> <td>    7.001</td> <td>   -1.963</td> <td> 0.050</td> <td>  -27.462</td> <td>   -0.018</td>\n</tr>\n<tr>\n  <th>Cu</th>        <td>  -53.7812</td> <td>   10.273</td> <td>   -5.235</td> <td> 0.000</td> <td>  -73.917</td> <td>  -33.645</td>\n</tr>\n<tr>\n  <th>Zn</th>        <td>   -3.9829</td> <td>    6.564</td> <td>   -0.607</td> <td> 0.544</td> <td>  -16.848</td> <td>    8.882</td>\n</tr>\n<tr>\n  <th>Ga</th>        <td>   11.4373</td> <td>    6.309</td> <td>    1.813</td> <td> 0.070</td> <td>   -0.929</td> <td>   23.804</td>\n</tr>\n<tr>\n  <th>Ge</th>        <td>  -48.6390</td> <td>    7.236</td> <td>   -6.721</td> <td> 0.000</td> <td>  -62.823</td> <td>  -34.455</td>\n</tr>\n<tr>\n  <th>As</th>        <td>  -34.2180</td> <td>    5.456</td> <td>   -6.272</td> <td> 0.000</td> <td>  -44.912</td> <td>  -23.524</td>\n</tr>\n<tr>\n  <th>Se</th>        <td>  -21.5930</td> <td>    4.909</td> <td>   -4.398</td> <td> 0.000</td> <td>  -31.216</td> <td>  -11.970</td>\n</tr>\n<tr>\n  <th>Br</th>        <td>    6.2667</td> <td>    8.524</td> <td>    0.735</td> <td> 0.462</td> <td>  -10.442</td> <td>   22.975</td>\n</tr>\n<tr>\n  <th>Kr</th>        <td> 2.941e-13</td> <td> 4.94e-14</td> <td>    5.954</td> <td> 0.000</td> <td> 1.97e-13</td> <td> 3.91e-13</td>\n</tr>\n<tr>\n  <th>Rb</th>        <td>   46.1221</td> <td>    6.515</td> <td>    7.080</td> <td> 0.000</td> <td>   33.352</td> <td>   58.892</td>\n</tr>\n<tr>\n  <th>Sr</th>        <td>    3.7730</td> <td>    6.710</td> <td>    0.562</td> <td> 0.574</td> <td>   -9.380</td> <td>   16.926</td>\n</tr>\n<tr>\n  <th>Y</th>         <td>   -7.4588</td> <td>    4.052</td> <td>   -1.841</td> <td> 0.066</td> <td>  -15.402</td> <td>    0.484</td>\n</tr>\n<tr>\n  <th>Zr</th>        <td>   -0.2442</td> <td>    3.554</td> <td>   -0.069</td> <td> 0.945</td> <td>   -7.211</td> <td>    6.722</td>\n</tr>\n<tr>\n  <th>Nb</th>        <td>   10.5669</td> <td>    3.536</td> <td>    2.988</td> <td> 0.003</td> <td>    3.636</td> <td>   17.498</td>\n</tr>\n<tr>\n  <th>Mo</th>        <td>   14.1377</td> <td>    6.704</td> <td>    2.109</td> <td> 0.035</td> <td>    0.998</td> <td>   27.278</td>\n</tr>\n<tr>\n  <th>Tc</th>        <td>   12.5309</td> <td>   11.727</td> <td>    1.069</td> <td> 0.285</td> <td>  -10.456</td> <td>   35.518</td>\n</tr>\n<tr>\n  <th>Ru</th>        <td>   18.3611</td> <td>   12.695</td> <td>    1.446</td> <td> 0.148</td> <td>   -6.523</td> <td>   43.246</td>\n</tr>\n<tr>\n  <th>Rh</th>        <td>   -3.4425</td> <td>    7.248</td> <td>   -0.475</td> <td> 0.635</td> <td>  -17.650</td> <td>   10.765</td>\n</tr>\n<tr>\n  <th>Pd</th>        <td>   -0.3406</td> <td>    7.375</td> <td>   -0.046</td> <td> 0.963</td> <td>  -14.797</td> <td>   14.116</td>\n</tr>\n<tr>\n  <th>Ag</th>        <td>  -83.2954</td> <td>    6.070</td> <td>  -13.722</td> <td> 0.000</td> <td>  -95.193</td> <td>  -71.398</td>\n</tr>\n<tr>\n  <th>Cd</th>        <td>  -16.9699</td> <td>   16.972</td> <td>   -1.000</td> <td> 0.317</td> <td>  -50.238</td> <td>   16.298</td>\n</tr>\n<tr>\n  <th>In</th>        <td>   17.6943</td> <td>    4.597</td> <td>    3.849</td> <td> 0.000</td> <td>    8.684</td> <td>   26.704</td>\n</tr>\n<tr>\n  <th>Sn</th>        <td>  -11.6178</td> <td>    8.600</td> <td>   -1.351</td> <td> 0.177</td> <td>  -28.474</td> <td>    5.239</td>\n</tr>\n<tr>\n  <th>Sb</th>        <td>   -2.7372</td> <td>   11.593</td> <td>   -0.236</td> <td> 0.813</td> <td>  -25.461</td> <td>   19.987</td>\n</tr>\n<tr>\n  <th>Te</th>        <td>   10.6440</td> <td>   12.424</td> <td>    0.857</td> <td> 0.392</td> <td>  -13.709</td> <td>   34.997</td>\n</tr>\n<tr>\n  <th>I</th>         <td>   19.1447</td> <td>    5.163</td> <td>    3.708</td> <td> 0.000</td> <td>    9.024</td> <td>   29.266</td>\n</tr>\n<tr>\n  <th>Xe</th>        <td>-1.127e-13</td> <td> 1.53e-14</td> <td>   -7.384</td> <td> 0.000</td> <td>-1.43e-13</td> <td>-8.28e-14</td>\n</tr>\n<tr>\n  <th>Cs</th>        <td>   25.0755</td> <td>    6.785</td> <td>    3.696</td> <td> 0.000</td> <td>   11.776</td> <td>   38.375</td>\n</tr>\n<tr>\n  <th>Ba</th>        <td>  206.5906</td> <td>    8.729</td> <td>   23.668</td> <td> 0.000</td> <td>  189.482</td> <td>  223.700</td>\n</tr>\n<tr>\n  <th>La</th>        <td>    2.4808</td> <td>    6.184</td> <td>    0.401</td> <td> 0.688</td> <td>   -9.640</td> <td>   14.602</td>\n</tr>\n<tr>\n  <th>Ce</th>        <td>  -14.2476</td> <td>    4.610</td> <td>   -3.091</td> <td> 0.002</td> <td>  -23.283</td> <td>   -5.212</td>\n</tr>\n<tr>\n  <th>Pr</th>        <td>   -5.0502</td> <td>   17.160</td> <td>   -0.294</td> <td> 0.769</td> <td>  -38.686</td> <td>   28.586</td>\n</tr>\n<tr>\n  <th>Nd</th>        <td>   -9.5486</td> <td>    3.949</td> <td>   -2.418</td> <td> 0.016</td> <td>  -17.288</td> <td>   -1.809</td>\n</tr>\n<tr>\n  <th>Pm</th>        <td>-3.345e-14</td> <td> 6.11e-15</td> <td>   -5.473</td> <td> 0.000</td> <td>-4.54e-14</td> <td>-2.15e-14</td>\n</tr>\n<tr>\n  <th>Sm</th>        <td>  -16.7340</td> <td>    5.206</td> <td>   -3.214</td> <td> 0.001</td> <td>  -26.938</td> <td>   -6.530</td>\n</tr>\n<tr>\n  <th>Eu</th>        <td>  -12.0473</td> <td>    5.592</td> <td>   -2.154</td> <td> 0.031</td> <td>  -23.008</td> <td>   -1.087</td>\n</tr>\n<tr>\n  <th>Gd</th>        <td>   -2.6984</td> <td>    3.748</td> <td>   -0.720</td> <td> 0.472</td> <td>  -10.045</td> <td>    4.648</td>\n</tr>\n<tr>\n  <th>Tb</th>        <td>   -5.1707</td> <td>    7.606</td> <td>   -0.680</td> <td> 0.497</td> <td>  -20.080</td> <td>    9.738</td>\n</tr>\n<tr>\n  <th>Dy</th>        <td>   17.9117</td> <td>    6.370</td> <td>    2.812</td> <td> 0.005</td> <td>    5.426</td> <td>   30.398</td>\n</tr>\n<tr>\n  <th>Ho</th>        <td>   15.7614</td> <td>    6.698</td> <td>    2.353</td> <td> 0.019</td> <td>    2.632</td> <td>   28.890</td>\n</tr>\n<tr>\n  <th>Er</th>        <td>   11.8549</td> <td>    5.263</td> <td>    2.253</td> <td> 0.024</td> <td>    1.540</td> <td>   22.170</td>\n</tr>\n<tr>\n  <th>Tm</th>        <td>    5.9715</td> <td>    5.436</td> <td>    1.099</td> <td> 0.272</td> <td>   -4.683</td> <td>   16.626</td>\n</tr>\n<tr>\n  <th>Yb</th>        <td>   48.4911</td> <td>   11.915</td> <td>    4.070</td> <td> 0.000</td> <td>   25.137</td> <td>   71.845</td>\n</tr>\n<tr>\n  <th>Lu</th>        <td>   27.5575</td> <td>    3.838</td> <td>    7.180</td> <td> 0.000</td> <td>   20.035</td> <td>   35.080</td>\n</tr>\n<tr>\n  <th>Hf</th>        <td>  -14.7490</td> <td>   14.629</td> <td>   -1.008</td> <td> 0.313</td> <td>  -43.423</td> <td>   13.925</td>\n</tr>\n<tr>\n  <th>Ta</th>        <td>   -2.4419</td> <td>   11.430</td> <td>   -0.214</td> <td> 0.831</td> <td>  -24.846</td> <td>   19.962</td>\n</tr>\n<tr>\n  <th>W</th>         <td>    0.7214</td> <td>    7.127</td> <td>    0.101</td> <td> 0.919</td> <td>  -13.248</td> <td>   14.691</td>\n</tr>\n<tr>\n  <th>Re</th>        <td>   -6.3622</td> <td>   10.415</td> <td>   -0.611</td> <td> 0.541</td> <td>  -26.778</td> <td>   14.053</td>\n</tr>\n<tr>\n  <th>Os</th>        <td>    6.0439</td> <td>    5.071</td> <td>    1.192</td> <td> 0.233</td> <td>   -3.896</td> <td>   15.984</td>\n</tr>\n<tr>\n  <th>Ir</th>        <td>    3.0530</td> <td>    8.998</td> <td>    0.339</td> <td> 0.734</td> <td>  -14.584</td> <td>   20.690</td>\n</tr>\n<tr>\n  <th>Pt</th>        <td>   22.0821</td> <td>    3.289</td> <td>    6.715</td> <td> 0.000</td> <td>   15.636</td> <td>   28.528</td>\n</tr>\n<tr>\n  <th>Au</th>        <td>  -43.6501</td> <td>   15.333</td> <td>   -2.847</td> <td> 0.004</td> <td>  -73.704</td> <td>  -13.596</td>\n</tr>\n<tr>\n  <th>Hg</th>        <td>   40.4470</td> <td>    7.291</td> <td>    5.548</td> <td> 0.000</td> <td>   26.156</td> <td>   54.738</td>\n</tr>\n<tr>\n  <th>Tl</th>        <td>   23.4660</td> <td>    3.160</td> <td>    7.426</td> <td> 0.000</td> <td>   17.272</td> <td>   29.660</td>\n</tr>\n<tr>\n  <th>Pb</th>        <td>   24.4639</td> <td>   10.411</td> <td>    2.350</td> <td> 0.019</td> <td>    4.057</td> <td>   44.871</td>\n</tr>\n<tr>\n  <th>Bi</th>        <td>   92.0024</td> <td>    5.392</td> <td>   17.063</td> <td> 0.000</td> <td>   81.434</td> <td>  102.571</td>\n</tr>\n<tr>\n  <th>Po</th>        <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n</tr>\n<tr>\n  <th>At</th>        <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n</tr>\n<tr>\n  <th>Rn</th>        <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td>1317.904</td> <th>  Durbin-Watson:     </th> <td>   1.965</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3671.459</td>\n</tr>\n<tr>\n  <th>Skew:</th>           <td>-0.459</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>       <td> 5.162</td>  <th>  Cond. No.          </th> <td>1.04e+16</td>\n</tr>\n</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[3] The smallest eigenvalue is 1.83e-27. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train full features model\n",
    "regressor_OLS = sm.regression.linear_model.OLS(y_train.values, X_train).fit()\n",
    "regressor_OLS.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Feature selection using Backward Elimination method\n",
    "def backwardelimination(x, y, sl):\n",
    "    numVars = x.shape[1]\n",
    "    for i in range(0, numVars):\n",
    "        regressor_OLS2 = sm.OLS(y, x).fit()\n",
    "        maxVar = regressor_OLS2.pvalues.max()\n",
    "        if maxVar > sl:\n",
    "            for j in range(0, numVars - i):\n",
    "                if (regressor_OLS2.pvalues[j].astype(float) == maxVar):\n",
    "                    x = x.drop(x.columns[j], axis=1)\n",
    "                    break\n",
    "        else:\n",
    "            break\n",
    "    return x\n",
    "\n",
    "X_modified = backwardelimination(X_train, y_train.values, 0.05)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                                 OLS Regression Results                                \n=======================================================================================\nDep. Variable:                      y   R-squared (uncentered):                   0.883\nModel:                            OLS   Adj. R-squared (uncentered):              0.882\nMethod:                 Least Squares   F-statistic:                              1139.\nDate:                Mon, 12 Dec 2022   Prob (F-statistic):                        0.00\nTime:                        13:16:56   Log-Likelihood:                         -67619.\nNo. Observations:               15980   AIC:                                  1.354e+05\nDf Residuals:                   15875   BIC:                                  1.363e+05\nDf Model:                         105                                                  \nCovariance Type:            nonrobust                                                  \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nfeature2     186.5770     12.387     15.062      0.000     162.297     210.857\nfeature3    -273.7818     12.096    -22.634      0.000    -297.491    -250.072\nfeature4     -93.2715     12.678     -7.357      0.000    -118.122     -68.421\nfeature5     167.8824     10.257     16.368      0.000     147.778     187.987\nfeature6     -34.0165      9.129     -3.726      0.000     -51.910     -16.123\nfeature8      38.4520      3.849      9.991      0.000      30.908      45.996\nfeature9      24.6656      4.521      5.456      0.000      15.804      33.527\nfeature10    -46.1130      4.904     -9.403      0.000     -55.726     -36.500\nfeature12   -161.6209     42.920     -3.766      0.000    -245.749     -77.492\nfeature14    139.1007     42.956      3.238      0.001      54.903     223.298\nfeature15     37.8005      5.950      6.353      0.000      26.138      49.463\nfeature16    -97.9320     24.453     -4.005      0.000    -145.862     -50.002\nfeature17    111.0526     10.051     11.049      0.000      91.351     130.754\nfeature18     68.2386      8.862      7.700      0.000      50.869      85.609\nfeature19     26.0763      4.561      5.718      0.000      17.137      35.016\nfeature20    -57.8258      9.985     -5.792      0.000     -77.397     -38.255\nfeature21    -10.8775      5.505     -1.976      0.048     -21.667      -0.088\nfeature22   -123.0996     28.083     -4.383      0.000    -178.145     -68.055\nfeature23    432.8909     24.798     17.457      0.000     384.284     481.498\nfeature24     60.3809     29.477      2.048      0.041       2.602     118.160\nfeature25   -365.5949     25.056    -14.591      0.000    -414.708    -316.482\nfeature27     46.5295      7.871      5.911      0.000      31.101      61.958\nfeature28     18.2761      6.338      2.884      0.004       5.853      30.699\nfeature29    -14.9811      4.013     -3.733      0.000     -22.846      -7.116\nfeature30    -37.1129      7.494     -4.953      0.000     -51.801     -22.424\nfeature32   -110.3452      8.126    -13.579      0.000    -126.274     -94.417\nfeature33    108.2378      9.221     11.738      0.000      90.164     126.312\nfeature36    -23.3550      6.821     -3.424      0.001     -36.726      -9.984\nfeature38    -24.3781      5.725     -4.258      0.000     -35.601     -13.156\nfeature39    -17.8189      5.622     -3.170      0.002     -28.838      -6.800\nfeature40     27.0380      6.377      4.240      0.000      14.538      39.538\nfeature43     92.7462     11.731      7.906      0.000      69.753     115.740\nfeature44     24.7500      5.730      4.319      0.000      13.518      35.982\nfeature45   -118.4646     11.281    -10.501      0.000    -140.577     -96.352\nfeature46     16.4091      4.993      3.286      0.001       6.622      26.196\nfeature47    -29.9923      4.008     -7.483      0.000     -37.849     -22.136\nfeature48   -114.5060      7.149    -16.016      0.000    -128.519    -100.493\nfeature49    -15.4233      4.962     -3.108      0.002     -25.149      -5.698\nfeature50    179.0661     10.016     17.878      0.000     159.433     198.699\nfeature51    -77.3913      6.452    -11.996      0.000     -90.037     -64.746\nfeature52    111.4128     22.056      5.051      0.000      68.181     154.644\nfeature53   -182.4432     22.398     -8.146      0.000    -226.346    -138.541\nfeature54    -73.8006     20.447     -3.609      0.000    -113.879     -33.722\nfeature55    131.3265     20.740      6.332      0.000      90.674     171.979\nfeature56    -39.0043      6.344     -6.148      0.000     -51.440     -26.569\nfeature57     41.0499      3.646     11.260      0.000      33.904      48.196\nfeature58    -23.0878      7.821     -2.952      0.003     -38.419      -7.757\nfeature59     61.7888      7.437      8.308      0.000      47.211      76.367\nfeature60    -30.3146     14.967     -2.025      0.043     -59.652      -0.977\nfeature61     37.2319      8.657      4.301      0.000      20.264      54.200\nfeature62    -25.1623      8.202     -3.068      0.002     -41.238      -9.086\nfeature63    203.4192      9.291     21.893      0.000     185.207     221.631\nfeature64    -17.6474      6.977     -2.529      0.011     -31.322      -3.972\nfeature65   -125.4677      6.374    -19.684      0.000    -137.962    -112.973\nfeature66     22.9235      2.955      7.758      0.000      17.132      28.715\nfeature68    -49.2296      5.618     -8.763      0.000     -60.241     -38.218\nfeature69    -80.9454      6.561    -12.337      0.000     -93.806     -68.085\nfeature70     75.4542      7.966      9.472      0.000      59.840      91.068\nfeature72     22.4364      5.530      4.057      0.000      11.598      33.275\nfeature73    -17.1450      5.789     -2.962      0.003     -28.492      -5.798\nfeature76    150.4732     22.488      6.691      0.000     106.395     194.552\nfeature77   -143.1756     10.415    -13.747      0.000    -163.590    -122.761\nfeature78     36.5240      2.764     13.213      0.000      31.106      41.942\nfeature79    -16.7966      4.734     -3.548      0.000     -26.077      -7.517\nfeature81    -60.9518      2.901    -21.013      0.000     -66.638     -55.266\nLi             6.2700      3.125      2.007      0.045       0.145      12.395\nO            -20.5915      6.684     -3.081      0.002     -33.692      -7.491\nF             32.8447      5.411      6.070      0.000      22.239      43.450\nNa            24.2646      6.244      3.886      0.000      12.025      36.504\nSi          -150.6669      7.541    -19.980      0.000    -165.448    -135.886\nP            -25.6618      5.781     -4.439      0.000     -36.993     -14.330\nS            -29.0585      3.597     -8.078      0.000     -36.110     -22.007\nCl           -17.7378      5.186     -3.421      0.001     -27.902      -7.573\nK             28.1956      4.447      6.341      0.000      19.480      36.911\nCa            31.8967      7.240      4.406      0.000      17.706      46.087\nFe            37.8478     10.963      3.452      0.001      16.358      59.337\nCo           -18.7731      8.966     -2.094      0.036     -36.347      -1.199\nNi           -16.5859      5.813     -2.853      0.004     -27.981      -5.191\nCu           -57.5593      9.647     -5.966      0.000     -76.469     -38.650\nGa            20.2617      4.991      4.059      0.000      10.478      30.045\nGe           -43.4298      6.885     -6.308      0.000     -56.925     -29.934\nAs           -31.1465      5.138     -6.062      0.000     -41.218     -21.075\nSe           -21.7863      4.680     -4.655      0.000     -30.959     -12.613\nRb            41.9275      5.864      7.150      0.000      30.434      53.421\nY             -8.1845      3.746     -2.185      0.029     -15.527      -0.842\nAg           -82.1402      5.892    -13.940      0.000     -93.690     -70.591\nIn            18.3137      4.393      4.169      0.000       9.704      26.924\nI             19.7702      5.103      3.874      0.000       9.768      29.773\nCs            22.5468      6.376      3.536      0.000      10.049      35.045\nBa           199.3787      6.643     30.014      0.000     186.358     212.399\nCe           -14.5408      4.551     -3.195      0.001     -23.462      -5.620\nNd           -11.1713      3.856     -2.897      0.004     -18.730      -3.612\nSm           -17.8704      5.116     -3.493      0.000     -27.897      -7.843\nEu           -11.9829      5.502     -2.178      0.029     -22.767      -1.199\nDy            17.8286      6.272      2.843      0.004       5.535      30.122\nHo            15.3385      6.587      2.329      0.020       2.427      28.249\nEr            10.5499      5.129      2.057      0.040       0.496      20.603\nYb            43.8516     11.366      3.858      0.000      21.572      66.131\nLu            26.6244      3.686      7.223      0.000      19.399      33.850\nPt            20.3139      3.144      6.460      0.000      14.150      26.477\nAu           -38.5807     13.871     -2.781      0.005     -65.769     -11.393\nHg            43.5721      6.865      6.347      0.000      30.117      57.028\nTl            23.3173      3.048      7.650      0.000      17.343      29.292\nPb            27.1600     10.275      2.643      0.008       7.020      47.300\nBi            95.6651      4.974     19.232      0.000      85.915     105.415\nPo                  0          0        nan        nan           0           0\nAt                  0          0        nan        nan           0           0\nRn                  0          0        nan        nan           0           0\n==============================================================================\nOmnibus:                     1302.551   Durbin-Watson:                   1.966\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             3619.048\nSkew:                          -0.454   Prob(JB):                         0.00\nKurtosis:                       5.147   Cond. No.                     1.10e+16\n==============================================================================\n\nNotes:\n[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[3] The smallest eigenvalue is 1.28e-27. This might indicate that there are\nstrong multicollinearity problems or that the design matrix is singular.\n\"\"\"",
      "text/html": "<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.883</td> \n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.882</td> \n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   1139.</td> \n</tr>\n<tr>\n  <th>Date:</th>             <td>Mon, 12 Dec 2022</td> <th>  Prob (F-statistic):</th>           <td>  0.00</td>  \n</tr>\n<tr>\n  <th>Time:</th>                 <td>13:16:56</td>     <th>  Log-Likelihood:    </th>          <td> -67619.</td> \n</tr>\n<tr>\n  <th>No. Observations:</th>      <td> 15980</td>      <th>  AIC:               </th>          <td>1.354e+05</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td> 15875</td>      <th>  BIC:               </th>          <td>1.363e+05</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>   105</td>      <th>                     </th>              <td> </td>    \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>feature2</th>  <td>  186.5770</td> <td>   12.387</td> <td>   15.062</td> <td> 0.000</td> <td>  162.297</td> <td>  210.857</td>\n</tr>\n<tr>\n  <th>feature3</th>  <td> -273.7818</td> <td>   12.096</td> <td>  -22.634</td> <td> 0.000</td> <td> -297.491</td> <td> -250.072</td>\n</tr>\n<tr>\n  <th>feature4</th>  <td>  -93.2715</td> <td>   12.678</td> <td>   -7.357</td> <td> 0.000</td> <td> -118.122</td> <td>  -68.421</td>\n</tr>\n<tr>\n  <th>feature5</th>  <td>  167.8824</td> <td>   10.257</td> <td>   16.368</td> <td> 0.000</td> <td>  147.778</td> <td>  187.987</td>\n</tr>\n<tr>\n  <th>feature6</th>  <td>  -34.0165</td> <td>    9.129</td> <td>   -3.726</td> <td> 0.000</td> <td>  -51.910</td> <td>  -16.123</td>\n</tr>\n<tr>\n  <th>feature8</th>  <td>   38.4520</td> <td>    3.849</td> <td>    9.991</td> <td> 0.000</td> <td>   30.908</td> <td>   45.996</td>\n</tr>\n<tr>\n  <th>feature9</th>  <td>   24.6656</td> <td>    4.521</td> <td>    5.456</td> <td> 0.000</td> <td>   15.804</td> <td>   33.527</td>\n</tr>\n<tr>\n  <th>feature10</th> <td>  -46.1130</td> <td>    4.904</td> <td>   -9.403</td> <td> 0.000</td> <td>  -55.726</td> <td>  -36.500</td>\n</tr>\n<tr>\n  <th>feature12</th> <td> -161.6209</td> <td>   42.920</td> <td>   -3.766</td> <td> 0.000</td> <td> -245.749</td> <td>  -77.492</td>\n</tr>\n<tr>\n  <th>feature14</th> <td>  139.1007</td> <td>   42.956</td> <td>    3.238</td> <td> 0.001</td> <td>   54.903</td> <td>  223.298</td>\n</tr>\n<tr>\n  <th>feature15</th> <td>   37.8005</td> <td>    5.950</td> <td>    6.353</td> <td> 0.000</td> <td>   26.138</td> <td>   49.463</td>\n</tr>\n<tr>\n  <th>feature16</th> <td>  -97.9320</td> <td>   24.453</td> <td>   -4.005</td> <td> 0.000</td> <td> -145.862</td> <td>  -50.002</td>\n</tr>\n<tr>\n  <th>feature17</th> <td>  111.0526</td> <td>   10.051</td> <td>   11.049</td> <td> 0.000</td> <td>   91.351</td> <td>  130.754</td>\n</tr>\n<tr>\n  <th>feature18</th> <td>   68.2386</td> <td>    8.862</td> <td>    7.700</td> <td> 0.000</td> <td>   50.869</td> <td>   85.609</td>\n</tr>\n<tr>\n  <th>feature19</th> <td>   26.0763</td> <td>    4.561</td> <td>    5.718</td> <td> 0.000</td> <td>   17.137</td> <td>   35.016</td>\n</tr>\n<tr>\n  <th>feature20</th> <td>  -57.8258</td> <td>    9.985</td> <td>   -5.792</td> <td> 0.000</td> <td>  -77.397</td> <td>  -38.255</td>\n</tr>\n<tr>\n  <th>feature21</th> <td>  -10.8775</td> <td>    5.505</td> <td>   -1.976</td> <td> 0.048</td> <td>  -21.667</td> <td>   -0.088</td>\n</tr>\n<tr>\n  <th>feature22</th> <td> -123.0996</td> <td>   28.083</td> <td>   -4.383</td> <td> 0.000</td> <td> -178.145</td> <td>  -68.055</td>\n</tr>\n<tr>\n  <th>feature23</th> <td>  432.8909</td> <td>   24.798</td> <td>   17.457</td> <td> 0.000</td> <td>  384.284</td> <td>  481.498</td>\n</tr>\n<tr>\n  <th>feature24</th> <td>   60.3809</td> <td>   29.477</td> <td>    2.048</td> <td> 0.041</td> <td>    2.602</td> <td>  118.160</td>\n</tr>\n<tr>\n  <th>feature25</th> <td> -365.5949</td> <td>   25.056</td> <td>  -14.591</td> <td> 0.000</td> <td> -414.708</td> <td> -316.482</td>\n</tr>\n<tr>\n  <th>feature27</th> <td>   46.5295</td> <td>    7.871</td> <td>    5.911</td> <td> 0.000</td> <td>   31.101</td> <td>   61.958</td>\n</tr>\n<tr>\n  <th>feature28</th> <td>   18.2761</td> <td>    6.338</td> <td>    2.884</td> <td> 0.004</td> <td>    5.853</td> <td>   30.699</td>\n</tr>\n<tr>\n  <th>feature29</th> <td>  -14.9811</td> <td>    4.013</td> <td>   -3.733</td> <td> 0.000</td> <td>  -22.846</td> <td>   -7.116</td>\n</tr>\n<tr>\n  <th>feature30</th> <td>  -37.1129</td> <td>    7.494</td> <td>   -4.953</td> <td> 0.000</td> <td>  -51.801</td> <td>  -22.424</td>\n</tr>\n<tr>\n  <th>feature32</th> <td> -110.3452</td> <td>    8.126</td> <td>  -13.579</td> <td> 0.000</td> <td> -126.274</td> <td>  -94.417</td>\n</tr>\n<tr>\n  <th>feature33</th> <td>  108.2378</td> <td>    9.221</td> <td>   11.738</td> <td> 0.000</td> <td>   90.164</td> <td>  126.312</td>\n</tr>\n<tr>\n  <th>feature36</th> <td>  -23.3550</td> <td>    6.821</td> <td>   -3.424</td> <td> 0.001</td> <td>  -36.726</td> <td>   -9.984</td>\n</tr>\n<tr>\n  <th>feature38</th> <td>  -24.3781</td> <td>    5.725</td> <td>   -4.258</td> <td> 0.000</td> <td>  -35.601</td> <td>  -13.156</td>\n</tr>\n<tr>\n  <th>feature39</th> <td>  -17.8189</td> <td>    5.622</td> <td>   -3.170</td> <td> 0.002</td> <td>  -28.838</td> <td>   -6.800</td>\n</tr>\n<tr>\n  <th>feature40</th> <td>   27.0380</td> <td>    6.377</td> <td>    4.240</td> <td> 0.000</td> <td>   14.538</td> <td>   39.538</td>\n</tr>\n<tr>\n  <th>feature43</th> <td>   92.7462</td> <td>   11.731</td> <td>    7.906</td> <td> 0.000</td> <td>   69.753</td> <td>  115.740</td>\n</tr>\n<tr>\n  <th>feature44</th> <td>   24.7500</td> <td>    5.730</td> <td>    4.319</td> <td> 0.000</td> <td>   13.518</td> <td>   35.982</td>\n</tr>\n<tr>\n  <th>feature45</th> <td> -118.4646</td> <td>   11.281</td> <td>  -10.501</td> <td> 0.000</td> <td> -140.577</td> <td>  -96.352</td>\n</tr>\n<tr>\n  <th>feature46</th> <td>   16.4091</td> <td>    4.993</td> <td>    3.286</td> <td> 0.001</td> <td>    6.622</td> <td>   26.196</td>\n</tr>\n<tr>\n  <th>feature47</th> <td>  -29.9923</td> <td>    4.008</td> <td>   -7.483</td> <td> 0.000</td> <td>  -37.849</td> <td>  -22.136</td>\n</tr>\n<tr>\n  <th>feature48</th> <td> -114.5060</td> <td>    7.149</td> <td>  -16.016</td> <td> 0.000</td> <td> -128.519</td> <td> -100.493</td>\n</tr>\n<tr>\n  <th>feature49</th> <td>  -15.4233</td> <td>    4.962</td> <td>   -3.108</td> <td> 0.002</td> <td>  -25.149</td> <td>   -5.698</td>\n</tr>\n<tr>\n  <th>feature50</th> <td>  179.0661</td> <td>   10.016</td> <td>   17.878</td> <td> 0.000</td> <td>  159.433</td> <td>  198.699</td>\n</tr>\n<tr>\n  <th>feature51</th> <td>  -77.3913</td> <td>    6.452</td> <td>  -11.996</td> <td> 0.000</td> <td>  -90.037</td> <td>  -64.746</td>\n</tr>\n<tr>\n  <th>feature52</th> <td>  111.4128</td> <td>   22.056</td> <td>    5.051</td> <td> 0.000</td> <td>   68.181</td> <td>  154.644</td>\n</tr>\n<tr>\n  <th>feature53</th> <td> -182.4432</td> <td>   22.398</td> <td>   -8.146</td> <td> 0.000</td> <td> -226.346</td> <td> -138.541</td>\n</tr>\n<tr>\n  <th>feature54</th> <td>  -73.8006</td> <td>   20.447</td> <td>   -3.609</td> <td> 0.000</td> <td> -113.879</td> <td>  -33.722</td>\n</tr>\n<tr>\n  <th>feature55</th> <td>  131.3265</td> <td>   20.740</td> <td>    6.332</td> <td> 0.000</td> <td>   90.674</td> <td>  171.979</td>\n</tr>\n<tr>\n  <th>feature56</th> <td>  -39.0043</td> <td>    6.344</td> <td>   -6.148</td> <td> 0.000</td> <td>  -51.440</td> <td>  -26.569</td>\n</tr>\n<tr>\n  <th>feature57</th> <td>   41.0499</td> <td>    3.646</td> <td>   11.260</td> <td> 0.000</td> <td>   33.904</td> <td>   48.196</td>\n</tr>\n<tr>\n  <th>feature58</th> <td>  -23.0878</td> <td>    7.821</td> <td>   -2.952</td> <td> 0.003</td> <td>  -38.419</td> <td>   -7.757</td>\n</tr>\n<tr>\n  <th>feature59</th> <td>   61.7888</td> <td>    7.437</td> <td>    8.308</td> <td> 0.000</td> <td>   47.211</td> <td>   76.367</td>\n</tr>\n<tr>\n  <th>feature60</th> <td>  -30.3146</td> <td>   14.967</td> <td>   -2.025</td> <td> 0.043</td> <td>  -59.652</td> <td>   -0.977</td>\n</tr>\n<tr>\n  <th>feature61</th> <td>   37.2319</td> <td>    8.657</td> <td>    4.301</td> <td> 0.000</td> <td>   20.264</td> <td>   54.200</td>\n</tr>\n<tr>\n  <th>feature62</th> <td>  -25.1623</td> <td>    8.202</td> <td>   -3.068</td> <td> 0.002</td> <td>  -41.238</td> <td>   -9.086</td>\n</tr>\n<tr>\n  <th>feature63</th> <td>  203.4192</td> <td>    9.291</td> <td>   21.893</td> <td> 0.000</td> <td>  185.207</td> <td>  221.631</td>\n</tr>\n<tr>\n  <th>feature64</th> <td>  -17.6474</td> <td>    6.977</td> <td>   -2.529</td> <td> 0.011</td> <td>  -31.322</td> <td>   -3.972</td>\n</tr>\n<tr>\n  <th>feature65</th> <td> -125.4677</td> <td>    6.374</td> <td>  -19.684</td> <td> 0.000</td> <td> -137.962</td> <td> -112.973</td>\n</tr>\n<tr>\n  <th>feature66</th> <td>   22.9235</td> <td>    2.955</td> <td>    7.758</td> <td> 0.000</td> <td>   17.132</td> <td>   28.715</td>\n</tr>\n<tr>\n  <th>feature68</th> <td>  -49.2296</td> <td>    5.618</td> <td>   -8.763</td> <td> 0.000</td> <td>  -60.241</td> <td>  -38.218</td>\n</tr>\n<tr>\n  <th>feature69</th> <td>  -80.9454</td> <td>    6.561</td> <td>  -12.337</td> <td> 0.000</td> <td>  -93.806</td> <td>  -68.085</td>\n</tr>\n<tr>\n  <th>feature70</th> <td>   75.4542</td> <td>    7.966</td> <td>    9.472</td> <td> 0.000</td> <td>   59.840</td> <td>   91.068</td>\n</tr>\n<tr>\n  <th>feature72</th> <td>   22.4364</td> <td>    5.530</td> <td>    4.057</td> <td> 0.000</td> <td>   11.598</td> <td>   33.275</td>\n</tr>\n<tr>\n  <th>feature73</th> <td>  -17.1450</td> <td>    5.789</td> <td>   -2.962</td> <td> 0.003</td> <td>  -28.492</td> <td>   -5.798</td>\n</tr>\n<tr>\n  <th>feature76</th> <td>  150.4732</td> <td>   22.488</td> <td>    6.691</td> <td> 0.000</td> <td>  106.395</td> <td>  194.552</td>\n</tr>\n<tr>\n  <th>feature77</th> <td> -143.1756</td> <td>   10.415</td> <td>  -13.747</td> <td> 0.000</td> <td> -163.590</td> <td> -122.761</td>\n</tr>\n<tr>\n  <th>feature78</th> <td>   36.5240</td> <td>    2.764</td> <td>   13.213</td> <td> 0.000</td> <td>   31.106</td> <td>   41.942</td>\n</tr>\n<tr>\n  <th>feature79</th> <td>  -16.7966</td> <td>    4.734</td> <td>   -3.548</td> <td> 0.000</td> <td>  -26.077</td> <td>   -7.517</td>\n</tr>\n<tr>\n  <th>feature81</th> <td>  -60.9518</td> <td>    2.901</td> <td>  -21.013</td> <td> 0.000</td> <td>  -66.638</td> <td>  -55.266</td>\n</tr>\n<tr>\n  <th>Li</th>        <td>    6.2700</td> <td>    3.125</td> <td>    2.007</td> <td> 0.045</td> <td>    0.145</td> <td>   12.395</td>\n</tr>\n<tr>\n  <th>O</th>         <td>  -20.5915</td> <td>    6.684</td> <td>   -3.081</td> <td> 0.002</td> <td>  -33.692</td> <td>   -7.491</td>\n</tr>\n<tr>\n  <th>F</th>         <td>   32.8447</td> <td>    5.411</td> <td>    6.070</td> <td> 0.000</td> <td>   22.239</td> <td>   43.450</td>\n</tr>\n<tr>\n  <th>Na</th>        <td>   24.2646</td> <td>    6.244</td> <td>    3.886</td> <td> 0.000</td> <td>   12.025</td> <td>   36.504</td>\n</tr>\n<tr>\n  <th>Si</th>        <td> -150.6669</td> <td>    7.541</td> <td>  -19.980</td> <td> 0.000</td> <td> -165.448</td> <td> -135.886</td>\n</tr>\n<tr>\n  <th>P</th>         <td>  -25.6618</td> <td>    5.781</td> <td>   -4.439</td> <td> 0.000</td> <td>  -36.993</td> <td>  -14.330</td>\n</tr>\n<tr>\n  <th>S</th>         <td>  -29.0585</td> <td>    3.597</td> <td>   -8.078</td> <td> 0.000</td> <td>  -36.110</td> <td>  -22.007</td>\n</tr>\n<tr>\n  <th>Cl</th>        <td>  -17.7378</td> <td>    5.186</td> <td>   -3.421</td> <td> 0.001</td> <td>  -27.902</td> <td>   -7.573</td>\n</tr>\n<tr>\n  <th>K</th>         <td>   28.1956</td> <td>    4.447</td> <td>    6.341</td> <td> 0.000</td> <td>   19.480</td> <td>   36.911</td>\n</tr>\n<tr>\n  <th>Ca</th>        <td>   31.8967</td> <td>    7.240</td> <td>    4.406</td> <td> 0.000</td> <td>   17.706</td> <td>   46.087</td>\n</tr>\n<tr>\n  <th>Fe</th>        <td>   37.8478</td> <td>   10.963</td> <td>    3.452</td> <td> 0.001</td> <td>   16.358</td> <td>   59.337</td>\n</tr>\n<tr>\n  <th>Co</th>        <td>  -18.7731</td> <td>    8.966</td> <td>   -2.094</td> <td> 0.036</td> <td>  -36.347</td> <td>   -1.199</td>\n</tr>\n<tr>\n  <th>Ni</th>        <td>  -16.5859</td> <td>    5.813</td> <td>   -2.853</td> <td> 0.004</td> <td>  -27.981</td> <td>   -5.191</td>\n</tr>\n<tr>\n  <th>Cu</th>        <td>  -57.5593</td> <td>    9.647</td> <td>   -5.966</td> <td> 0.000</td> <td>  -76.469</td> <td>  -38.650</td>\n</tr>\n<tr>\n  <th>Ga</th>        <td>   20.2617</td> <td>    4.991</td> <td>    4.059</td> <td> 0.000</td> <td>   10.478</td> <td>   30.045</td>\n</tr>\n<tr>\n  <th>Ge</th>        <td>  -43.4298</td> <td>    6.885</td> <td>   -6.308</td> <td> 0.000</td> <td>  -56.925</td> <td>  -29.934</td>\n</tr>\n<tr>\n  <th>As</th>        <td>  -31.1465</td> <td>    5.138</td> <td>   -6.062</td> <td> 0.000</td> <td>  -41.218</td> <td>  -21.075</td>\n</tr>\n<tr>\n  <th>Se</th>        <td>  -21.7863</td> <td>    4.680</td> <td>   -4.655</td> <td> 0.000</td> <td>  -30.959</td> <td>  -12.613</td>\n</tr>\n<tr>\n  <th>Rb</th>        <td>   41.9275</td> <td>    5.864</td> <td>    7.150</td> <td> 0.000</td> <td>   30.434</td> <td>   53.421</td>\n</tr>\n<tr>\n  <th>Y</th>         <td>   -8.1845</td> <td>    3.746</td> <td>   -2.185</td> <td> 0.029</td> <td>  -15.527</td> <td>   -0.842</td>\n</tr>\n<tr>\n  <th>Ag</th>        <td>  -82.1402</td> <td>    5.892</td> <td>  -13.940</td> <td> 0.000</td> <td>  -93.690</td> <td>  -70.591</td>\n</tr>\n<tr>\n  <th>In</th>        <td>   18.3137</td> <td>    4.393</td> <td>    4.169</td> <td> 0.000</td> <td>    9.704</td> <td>   26.924</td>\n</tr>\n<tr>\n  <th>I</th>         <td>   19.7702</td> <td>    5.103</td> <td>    3.874</td> <td> 0.000</td> <td>    9.768</td> <td>   29.773</td>\n</tr>\n<tr>\n  <th>Cs</th>        <td>   22.5468</td> <td>    6.376</td> <td>    3.536</td> <td> 0.000</td> <td>   10.049</td> <td>   35.045</td>\n</tr>\n<tr>\n  <th>Ba</th>        <td>  199.3787</td> <td>    6.643</td> <td>   30.014</td> <td> 0.000</td> <td>  186.358</td> <td>  212.399</td>\n</tr>\n<tr>\n  <th>Ce</th>        <td>  -14.5408</td> <td>    4.551</td> <td>   -3.195</td> <td> 0.001</td> <td>  -23.462</td> <td>   -5.620</td>\n</tr>\n<tr>\n  <th>Nd</th>        <td>  -11.1713</td> <td>    3.856</td> <td>   -2.897</td> <td> 0.004</td> <td>  -18.730</td> <td>   -3.612</td>\n</tr>\n<tr>\n  <th>Sm</th>        <td>  -17.8704</td> <td>    5.116</td> <td>   -3.493</td> <td> 0.000</td> <td>  -27.897</td> <td>   -7.843</td>\n</tr>\n<tr>\n  <th>Eu</th>        <td>  -11.9829</td> <td>    5.502</td> <td>   -2.178</td> <td> 0.029</td> <td>  -22.767</td> <td>   -1.199</td>\n</tr>\n<tr>\n  <th>Dy</th>        <td>   17.8286</td> <td>    6.272</td> <td>    2.843</td> <td> 0.004</td> <td>    5.535</td> <td>   30.122</td>\n</tr>\n<tr>\n  <th>Ho</th>        <td>   15.3385</td> <td>    6.587</td> <td>    2.329</td> <td> 0.020</td> <td>    2.427</td> <td>   28.249</td>\n</tr>\n<tr>\n  <th>Er</th>        <td>   10.5499</td> <td>    5.129</td> <td>    2.057</td> <td> 0.040</td> <td>    0.496</td> <td>   20.603</td>\n</tr>\n<tr>\n  <th>Yb</th>        <td>   43.8516</td> <td>   11.366</td> <td>    3.858</td> <td> 0.000</td> <td>   21.572</td> <td>   66.131</td>\n</tr>\n<tr>\n  <th>Lu</th>        <td>   26.6244</td> <td>    3.686</td> <td>    7.223</td> <td> 0.000</td> <td>   19.399</td> <td>   33.850</td>\n</tr>\n<tr>\n  <th>Pt</th>        <td>   20.3139</td> <td>    3.144</td> <td>    6.460</td> <td> 0.000</td> <td>   14.150</td> <td>   26.477</td>\n</tr>\n<tr>\n  <th>Au</th>        <td>  -38.5807</td> <td>   13.871</td> <td>   -2.781</td> <td> 0.005</td> <td>  -65.769</td> <td>  -11.393</td>\n</tr>\n<tr>\n  <th>Hg</th>        <td>   43.5721</td> <td>    6.865</td> <td>    6.347</td> <td> 0.000</td> <td>   30.117</td> <td>   57.028</td>\n</tr>\n<tr>\n  <th>Tl</th>        <td>   23.3173</td> <td>    3.048</td> <td>    7.650</td> <td> 0.000</td> <td>   17.343</td> <td>   29.292</td>\n</tr>\n<tr>\n  <th>Pb</th>        <td>   27.1600</td> <td>   10.275</td> <td>    2.643</td> <td> 0.008</td> <td>    7.020</td> <td>   47.300</td>\n</tr>\n<tr>\n  <th>Bi</th>        <td>   95.6651</td> <td>    4.974</td> <td>   19.232</td> <td> 0.000</td> <td>   85.915</td> <td>  105.415</td>\n</tr>\n<tr>\n  <th>Po</th>        <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n</tr>\n<tr>\n  <th>At</th>        <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n</tr>\n<tr>\n  <th>Rn</th>        <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td>1302.551</td> <th>  Durbin-Watson:     </th> <td>   1.966</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3619.048</td>\n</tr>\n<tr>\n  <th>Skew:</th>           <td>-0.454</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>       <td> 5.147</td>  <th>  Cond. No.          </th> <td>1.10e+16</td>\n</tr>\n</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[3] The smallest eigenvalue is 1.28e-27. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model with choosen features\n",
    "regressor_OLS_BE = sm.OLS(y_train.values, X_modified).fit()\n",
    "regressor_OLS_BE.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QQ-Plot of residuals\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkkAAAGxCAYAAAB2qSLdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABUCElEQVR4nO3deXhU1cE/8O/sk53sISxZQAUBtSQKoaaIYBBsqzZUtJVFxZpatBD5vbK4IFaDSClaWSoCFquAr4D1rbEQFRAlgkAQkJQihASyEBIge2YyM+f3x+ROGDJJZiYzuUPy/TzPPJA7Z+45cwmTb852FUIIASIiIiKyo5S7AURERES+iCGJiIiIyAGGJCIiIiIHGJKIiIiIHGBIIiIiInKAIYmIiIjIAYYkIiIiIgcYkoiIiIgcYEgiIiIicoAhiciL3n33XSgUCttDrVajb9++eOSRR1BcXGwrt2vXLigUCuzatcvlOvbu3YuFCxfi8uXLnmt4s82bN2PIkCHw8/ODQqHA4cOHPV6HK+644w7ccccdHZY7c+YMFAoF3n33XZ9oT1vi4+Mxffp029fufh+sXLnS5ffqqK7p06cjMDDQpfN0pL3vz85ePyJvU8vdAKKeYP369Rg0aBAaGhrw1VdfISsrC7t378bRo0cREBDQqXPv3bsXL730EqZPn45evXp5psEALly4gClTpuDuu+/GypUrodPpcP3113vs/O5YuXKlrPV72/Dhw5Gbm4sbb7zRpdetXLkSERERdoHLW3W5qr3vz+7+70nXPoYkoi4wdOhQJCcnAwDGjBkDs9mMl19+GR9//DF++9vfytw6x/773/+iqakJDz/8MEaPHu3y6xsaGqDX66FQKDzWJm//QJdbcHAwRo4c6dU6mpqaoFAouqSujnT3f0+69nG4jUgG0g+nwsLCdst98sknSElJgb+/P4KCgnDXXXchNzfX9vzChQvx//7f/wMAJCQk2Ib1Ohqu6ei806dPx+233w4AmDx5MhQKRbvDItKw4o4dO/Doo48iMjIS/v7+MBgMAKzDdikpKQgICEBgYCDGjx+PvLw8u3OcPn0aDz74IGJjY6HT6RAdHY2xY8faDfE5Gp4pKSnBAw88gKCgIISEhGDy5MkoKytr1ca2hnamT5+O+Ph4u2MvvfQSRowYgbCwMAQHB2P48OFYu3Yt3L0feFNTE/7nf/4HMTEx8Pf3x+233479+/e3KudoCKyj6xIfH48ffvgBu3fvtv37S+9HOt97772HZ555Bn369IFOp8OPP/7Y7tDeDz/8gLFjxyIgIACRkZGYOXMm6uvrbc+3N5ypUCiwcOFCAB1/fzr6N7l48SKefPJJ9OnTB1qtFomJiViwYIHte+nKembOnIn33nsPgwcPhr+/P26++Wb861//avsfgshF7EkiksGPP/4IAIiMjGyzzAcffIDf/va3SEtLw8aNG2EwGLBkyRLccccd+OKLL3D77bdjxowZuHjxIv76179i69at6N27N4D2f0N35rzPP/88brvtNvzhD3/Aq6++ijFjxiA4OLjD9/Xoo4/innvuwXvvvYe6ujpoNBq8+uqreO655/DII4/gueeeg9FoxOuvv47U1FTs37/f1taJEyfCbDZjyZIl6N+/PyoqKrB3795251o1NDRg3LhxKCkpQVZWFq6//np8+umnmDx5codtbc+ZM2fwxBNPoH///gCAb7/9Fk899RSKi4vxwgsvuHy+xx9/HBs2bMCcOXNw11134dixY/jVr36FmpqaDl/b0XXZtm0bJk2ahJCQENvwlU6nszvHvHnzkJKSgtWrV0OpVCIqKsphkASsgW7ixIl44oknMHfuXOzduxd/+tOfUFhYiP/7v/9z6X27+v3Z2NiIMWPG4NSpU3jppZdw0003Yc+ePcjKysLhw4fx6aef2pX/9NNP8d1332HRokUIDAzEkiVLcP/99+PEiRNITEx0qa1EDgki8pr169cLAOLbb78VTU1NoqamRvzrX/8SkZGRIigoSJSVlQkhhNi5c6cAIHbu3CmEEMJsNovY2FgxbNgwYTabbeerqakRUVFRYtSoUbZjr7/+ugAgCgoKOmyPK+eV2vS///u/Tr/PqVOn2h0vKioSarVaPPXUU3bHa2pqRExMjHjggQeEEEJUVFQIAGL58uXt1jN69GgxevRo29erVq0SAMQ///lPu3KPP/64ACDWr1/f5msl06ZNE3FxcW3WaTabRVNTk1i0aJEIDw8XFoulw3NeKT8/XwAQs2fPtjv+/vvvCwBi2rRptmNXfx84e12GDBnisB3S+X72s5+1+ZxUlxDWawFAvPHGG3ZlX3nlFQFAfP3110IIIQoKClpdXwkA8eKLL9q+bu/78+rrt3r1agFAfPjhh3blXnvtNQFA7Nixw66e6OhoUV1dbTtWVlYmlEqlyMrKalUXkTs43EbUBUaOHAmNRoOgoCD8/Oc/R0xMDD777DNER0c7LH/ixAmUlJRgypQpUCpb/psGBgYiPT0d3377rd3wh7O8dV5Jenq63dfbt2+HyWTC1KlTYTKZbA+9Xo/Ro0fbhl3CwsIwYMAAvP7661i2bBny8vJgsVg6rG/nzp0ICgrCL3/5S7vjv/nNb9x+DwDw5ZdfYty4cQgJCYFKpYJGo8ELL7yAyspKlJeXu3SunTt3AkCruWcPPPAA1Or2O/PdvS5Xu/rfpSNXt1W6ntJ78ZYvv/wSAQEBmDRpkt1xaUL6F198YXd8zJgxCAoKsn0dHR2NqKioDoexiZzFkETUBTZs2IDvvvsOeXl5KCkpwZEjR/DTn/60zfKVlZUAYBueuFJsbCwsFgsuXbrkcju8dV7J1ec9f/48AODWW2+FRqOxe2zevBkVFRUArPNLvvjiC4wfPx5LlizB8OHDERkZiaeffrrdIanKykqHQTMmJsbt97B//36kpaUBANasWYNvvvkG3333HRYsWADAOsTnCumaX90mtVqN8PDwdl/r7nW5mqN/77Y4apfUdum9eEtlZSViYmJaTfaPioqCWq1uVb+j66fT6Vz+NyJqC+ckEXWBwYMH21a3OUP68C8tLW31XElJCZRKJUJDQ11uh7fOK7n6h1tERAQA4KOPPkJcXFy7r42Li8PatWsBWFfWffjhh1i4cCGMRiNWr17t8DXh4eEOJ0A7mm+j1+tRVVXV6rgU1CSbNm2CRqPBv/71L+j1etvxjz/+uN32t0W65mVlZejTp4/tuMlkcip0uHNdrubKCkOpXVcGEOl6Ssek63L1ZOrOhqjw8HDs27cPQgi7NpeXl8NkMtm+n4i6CnuSiHzQDTfcgD59+uCDDz6wW1FVV1eHLVu22FamAS2TdJ357dmV83rC+PHjoVarcerUKSQnJzt8OHL99dfjueeew7Bhw3Do0KE2zz9mzBjU1NTgk08+sTv+wQcftCobHx+P//73v3Y/2CsrK7F37167ctKmnyqVynasoaEB7733nlPv+WrS6q3333/f7viHH34Ik8nk0rnaui6e7j25uq3S9ZTeS3R0NPR6PY4cOWJX7p///Gerc7ny/Tl27FjU1ta2CqQbNmywPU/UldiTROSDlEollixZgt/+9rf4+c9/jieeeAIGgwGvv/46Ll++jMWLF9vKDhs2DADwxhtvYNq0adBoNLjhhhvs5mq4c15PiI+Px6JFi7BgwQKcPn0ad999N0JDQ3H+/Hns378fAQEBeOmll3DkyBHMnDkTv/71r3HddddBq9Xiyy+/xJEjRzB37tw2zz916lT85S9/wdSpU/HKK6/guuuuQ3Z2NrZv396q7JQpU/C3v/0NDz/8MB5//HFUVlZiyZIlrVbt3XPPPVi2bBl+85vf4He/+x0qKyuxdOnSVivGnDV48GA8/PDDWL58OTQaDcaNG4djx45h6dKlHa4YdPa6DBs2DJs2bcLmzZuRmJgIvV5v+75wlVarxZ///GfU1tbi1ltvta1umzBhgm1bCIVCgYcffhjr1q3DgAEDcPPNN2P//v0Ow6kr359Tp07FihUrMG3aNJw5cwbDhg3D119/jVdffRUTJ07EuHHj3HpPRG6TeeI4Ubcmrfr67rvv2i3naKWREEJ8/PHHYsSIEUKv14uAgAAxduxY8c0337R6/bx580RsbKxQKpUOz3M1Z87rzuq2tt7nxx9/LMaMGSOCg4OFTqcTcXFxYtKkSeLzzz8XQghx/vx5MX36dDFo0CAREBAgAgMDxU033ST+8pe/CJPJZDuPo9Vk586dE+np6SIwMFAEBQWJ9PR0sXfvXoerr/7+97+LwYMHC71eL2688UaxefNmh6vb1q1bJ2644Qah0+lEYmKiyMrKEmvXrm21SsuZ1W1CCGEwGMQzzzwjoqKihF6vFyNHjhS5ubkiLi6u3dVtzl6XM2fOiLS0NBEUFCQA2N5Pe/+Gba1uCwgIEEeOHBF33HGH8PPzE2FhYeL3v/+9qK2ttXt9VVWVmDFjhoiOjhYBAQHiF7/4hThz5kyr1W1CtP396ej6VVZWioyMDNG7d2+hVqtFXFycmDdvnmhsbLQrB0D84Q9/aPW+rr6mRJ2hEMLN3dGIiIiIujHOSSIiIiJygCGJiIiIyAGGJCIiIiIHGJKIiIiIHGBIIiIiInKAIYmIiIjIAW4m6SaLxYKSkhIEBQW5tOU/ERERyUcIgZqaGsTGxtrd6NsRhiQ3lZSUoF+/fnI3g4iIiNxw9uxZ9O3bt90yDElukrbUP3v2bIe3FiAiIiLfUF1djX79+jm8Nc7VGJLcJA2xBQcHMyQRERFdY5yZKsOJ20REREQOMCQREREROcCQREREROSA7CFp5cqVSEhIgF6vR1JSEvbs2dNu+d27dyMpKQl6vR6JiYlYvXq13fNbt25FcnIyevXqhYCAANxyyy147733Ol0vERER9SyyhqTNmzdj1qxZWLBgAfLy8pCamooJEyagqKjIYfmCggJMnDgRqampyMvLw/z58/H0009jy5YttjJhYWFYsGABcnNzceTIETzyyCN45JFHsH37drfrJSIiop5HIYQQclU+YsQIDB8+HKtWrbIdGzx4MO677z5kZWW1Kv/ss8/ik08+QX5+vu1YRkYGvv/+e+Tm5rZZz/Dhw3HPPffg5ZdfdqteR6qrqxESEoKqqiqubiMiIrpGuPLzW7aeJKPRiIMHDyItLc3ueFpaGvbu3evwNbm5ua3Kjx8/HgcOHEBTU1Or8kIIfPHFFzhx4gR+9rOfuV0vABgMBlRXV9s9iIiIqPuSLSRVVFTAbDYjOjra7nh0dDTKysocvqasrMxheZPJhIqKCtuxqqoqBAYGQqvV4p577sFf//pX3HXXXW7XCwBZWVkICQmxPbjbNhERUfcm+8TtqzdzEkK0u8GTo/JXHw8KCsLhw4fx3Xff4ZVXXkFmZiZ27drVqXrnzZuHqqoq2+Ps2bPtvi8iIiK6tsm243ZERARUKlWr3pvy8vJWvTySmJgYh+XVajXCw8Ntx5RKJQYOHAgAuOWWW5Cfn4+srCzccccdbtULADqdDjqdzqX3SERERNcu2XqStFotkpKSkJOTY3c8JycHo0aNcvialJSUVuV37NiB5ORkaDSaNusSQsBgMLhdLxEREfU8st67LTMzE1OmTEFycjJSUlLw9ttvo6ioCBkZGQCsQ1zFxcXYsGEDAOtKtrfeeguZmZl4/PHHkZubi7Vr12Ljxo22c2ZlZSE5ORkDBgyA0WhEdnY2NmzYYLeSraN6iYiIiGQNSZMnT0ZlZSUWLVqE0tJSDB06FNnZ2YiLiwMAlJaW2u1dlJCQgOzsbMyePRsrVqxAbGws3nzzTaSnp9vK1NXV4cknn8S5c+fg5+eHQYMG4R//+AcmT57sdL1E5Bu+/M95nDxfi4dHxiFAx/txE1HXknWfpGsZ90ki8q69P1bgN+/sAwDcdWM01kxNlrlFRNQdXBP7JBERteedrwtsf885fh6nLtTK2Boi6okYkojI5zQ2mfHNj9a9z/r08gMA/PtY2/uYERF5A0MSEfmc789ehsFkQVSQDr/7WSIAYF/BRZlbRUQ9DUMSEfmc/FLrbX9u6tsLyfGhAIC8wkvgFEoi6koMSUTkc06crwEADIoJwvXRQVArFagxmFBS1Shzy4ioJ2FIIiKfc/pCHQBgYFQgNCol4iMCAAA/lnPyNhF1HYYkIvI5ZdXWHqPY5knbAyMDATAkEVHXYkgiIp8ihEBp87Ba7xA9AGuPEgD8WF4jW7uIqOdhSCIin3KxzgijyQIAiA62hqTrotmTRERdjyGJiHyK1IsUEaiDVm39iBrQPNxWUFEnW7uIqOdhSCIin3L1UBvQsqFkRa0RjU1mWdpFRD0PQxIR+ZSyqgYA9iGpl78Geo2y+XluA0BEXYMhiYh8SomDniSFQmFb6VZyuUGWdhFRz8OQREQ+pbzaAACICtbbHY8NaQ5J7Ekioi7CkEREPqWqwQgACPXX2h2P7WUNTexJIqKuwpBERD7lcn0TAOs8pCtJw22lVQxJRNQ1GJKIyKdUNTSHJL+rQlLzcFvxZQ63EVHXYEgiIp9yuTkkBV8VkmKaJ3Kf55wkIuoiDElE5DOEEC09SVcNt0UE6gAAFbWGLm8XEfVMDElE5DMamyy2W5KEXNWTFBFknch9sd4Ik9nS5W0jop6HIYmIfIbUi6RSKhCoU9s9F+avhUIBCGENSkRE3saQREQ+43Lz8v8QPw0UCoXdc2qVEmHN2wJU1jIkEZH3MSQRkc+oqne8sk3CeUlE1JUYkojIZ0jDbSH+bYSk5nlJDElE1BUYkojIZ0jL/6+etC2x9STVcLiNiLyPIYmIfEZ1GxtJSjjcRkRdiSGJiHxGVRsbSUqkkHSBIYmIugBDEhH5jFqDCQBaLf+XhAc275VUx+E2IvI+hiQi8hl1zSEpoI2QFNq8BcCl5lVwRETexJBERD6jzmgGAARoVQ6fD21e9XaZm0kSURdgSCIin9FRT1IvW0hiTxIReR9DEhH5jHpDc09SmyHJOtxW3dgEs0V0WbuIqGdiSCIin1HbUU9S86o3IVpWwhEReQtDEhH5jHpjc0hqY06SWqVEUHOA4rwkIvI2hiQi8hm1HQy3AUCvAGtvEle4EZG3MSQRkc9o6UlqOyRJ2wCwJ4mIvI0hiYh8gsUiUC9tAaBzPNwGtNzXjSvciMjbGJKIyCfUN5ltf29vuK1lQ0n2JBGRdzEkEZFPkPZIUikV0Knb/mjiXklE1FUYkojIJ0ghyV+rgkKhaLNcL/YkEVEXYUgiIp9QJ61sa2fSNtAyJ6mm0eT1NhFRz8aQREQ+oU5a2dbOpG0ACNJbQ1R1I4fbiMi7GJKIyCd0dN82SbCePUlE1DUYkojIJ9QZnRtuC5Z6knhbEiLyMoYkIvIJLT1J7Q+3BTfPSeJwGxF5G0MSEfkEaSNJvw57kjjcRkRdQ/aQtHLlSiQkJECv1yMpKQl79uxpt/zu3buRlJQEvV6PxMRErF692u75NWvWIDU1FaGhoQgNDcW4ceOwf/9+uzILFy6EQqGwe8TExHj8vRGR8xqbN5P01zg3cbveaEaT2eL1dhFRzyVrSNq8eTNmzZqFBQsWIC8vD6mpqZgwYQKKioocli8oKMDEiRORmpqKvLw8zJ8/H08//TS2bNliK7Nr1y489NBD2LlzJ3Jzc9G/f3+kpaWhuLjY7lxDhgxBaWmp7XH06FGvvlciap8UkvSa9j+WpJAEsDeJiLyr/X5tL1u2bBkee+wxzJgxAwCwfPlybN++HatWrUJWVlar8qtXr0b//v2xfPlyAMDgwYNx4MABLF26FOnp6QCA999/3+41a9aswUcffYQvvvgCU6dOtR1Xq9XsPSLyIQ3Nw216bfs9SWqVEgFaFeqMZtQ0NiEsQNsVzSOiHki2niSj0YiDBw8iLS3N7nhaWhr27t3r8DW5ubmtyo8fPx4HDhxAU5PjSZz19fVoampCWFiY3fGTJ08iNjYWCQkJePDBB3H69Ol222swGFBdXW33ICLPaWjuSfLrYLgNAIKa5yVVN7AniYi8R7aQVFFRAbPZjOjoaLvj0dHRKCsrc/iasrIyh+VNJhMqKiocvmbu3Lno06cPxo0bZzs2YsQIbNiwAdu3b8eaNWtQVlaGUaNGobKyss32ZmVlISQkxPbo16+fs2+ViJzQ2GSdX6R3IiQF+3FDSSLyPtknbl99jyYhRLv3bXJU3tFxAFiyZAk2btyIrVu3Qq/X245PmDAB6enpGDZsGMaNG4dPP/0UAPD3v/+9zXrnzZuHqqoq2+Ps2bMdvzkiclqjGz1JNQxJRORFss1JioiIgEqlatVrVF5e3qq3SBITE+OwvFqtRnh4uN3xpUuX4tVXX8Xnn3+Om266qd22BAQEYNiwYTh58mSbZXQ6HXQ6XbvnISL3uTLc1rKhJIfbiMh7ZOtJ0mq1SEpKQk5Ojt3xnJwcjBo1yuFrUlJSWpXfsWMHkpOTodFobMdef/11vPzyy/j3v/+N5OTkDttiMBiQn5+P3r17u/FOiMgTpInbug5WtwHcUJKIuoasw22ZmZl45513sG7dOuTn52P27NkoKipCRkYGAOsQ15Ur0jIyMlBYWIjMzEzk5+dj3bp1WLt2LebMmWMrs2TJEjz33HNYt24d4uPjUVZWhrKyMtTW1trKzJkzB7t370ZBQQH27duHSZMmobq6GtOmTeu6N09EdhpNrgy3SXOS2JNERN4j6xYAkydPRmVlJRYtWoTS0lIMHToU2dnZiIuLAwCUlpba7ZmUkJCA7OxszJ49GytWrEBsbCzefPNN2/J/wLo5pdFoxKRJk+zqevHFF7Fw4UIAwLlz5/DQQw+hoqICkZGRGDlyJL799ltbvUTU9RpsO247M9wmrW5jTxIReY+sIQkAnnzySTz55JMOn3v33XdbHRs9ejQOHTrU5vnOnDnTYZ2bNm1ytnlE1EVaNpN0ZnUbh9uIyPtkX91GRAS0bAHgynAbd9wmIm9iSCIin9DgSk8Sh9uIqAswJBGRT2hw8t5tACduE1HXYEgiItlZLAJGk/PDbdKcJG4mSUTexJBERLKTlv8DXN1GRL6DIYmIZCct/wcAvdr5HbdrDSZYLMJr7SKino0hiYhk19g81KZVK6FUtn3vRol07zaLAOqMnJdERN7BkEREsrNtJOnEfCTAOrlb3RymuA0AEXkLQxIRya7RhZvbAoBCoeBeSUTkdQxJRCS7RheW/0ukITeucCMib2FIIiLZubKRpCTYjz1JRORdDElEJDtXbm4rCdLx/m1E5F0MSUQkO2l1mzPL/yWck0RE3saQRESya3SnJ0nPniQi8i6GJCKSXYOLq9sA9iQRkfcxJBGR7KTVbToXVrcF20ISe5KIyDsYkohIdu70JLXc5JY9SUTkHQxJRCQ7DrcRkS9iSCIi2UkTt13ZJ4mbSRKRtzEkEZHsGpusWwC4trrN2pNU3cCeJCLyDoYkIpKdOztusyeJiLyNIYmIZNfg1r3bOCeJiLyLIYmIZNfYiYnbtUYTLBbhlXYRUc/GkEREsnMnJAU3D7cJYQ1KRESexpBERLKzDbe5MHFbr1FBq7J+hHHIjYi8gSGJiGQnrW5z5Qa3wJXzkjh5m4g8jyGJiGTX4MYNbgFuA0BE3sWQRESyc2dOEsBtAIjIuxiSiEh2jW5sAQBwGwAi8i6GJCKSlRDCrXu3AS0r3NiTRETewJBERLIymi2QtjlyZXUbcMWcJPYkEZEXMCQRkayklW2AO6vbpJ4khiQi8jyGJCKSlTQfSaVUQKNSuPRabgFARN7EkEREsrIt/9eooFC4F5I43EZE3sCQRESyajS5t7IN4MRtIvIuhiQikpXUk6RzcT4SAAT7cQsAIvIehiQikpW0/N/fxZVtADeTJCLvYkgiIlm1bCTpTkhiTxIReQ9DEhHJStoCwNWNJAFuAUBE3sWQRESykuYkubqRJNDSk1RrMMEs7UhJROQhDElEJCtpTpJe7frHkRSSAKCWvUlE5GEMSUQkK2lOkp8bPUk6tQq65nBVzcnbRORhDElEJKtGN29uK+G8JCLyFoYkIpJVQydWtwFAMG9NQkRewpBERLKSVre5G5K4DQAReQtDEhHJqsFTw20G9iQRkWfJHpJWrlyJhIQE6PV6JCUlYc+ePe2W3717N5KSkqDX65GYmIjVq1fbPb9mzRqkpqYiNDQUoaGhGDduHPbv39/peonIOxqlG9xq3fs4Yk8SEXmLrCFp8+bNmDVrFhYsWIC8vDykpqZiwoQJKCoqcli+oKAAEydORGpqKvLy8jB//nw8/fTT2LJli63Mrl278NBDD2Hnzp3Izc1F//79kZaWhuLiYrfrJSLvabnBrbtzkqw9SdUN7EkiIs9SCCFk24FtxIgRGD58OFatWmU7NnjwYNx3333IyspqVf7ZZ5/FJ598gvz8fNuxjIwMfP/998jNzXVYh9lsRmhoKN566y1MnTrVrXodqa6uRkhICKqqqhAcHOzUa4iotUfW78fOExewZNJNeCC5n8uv/9O/juOdrwvwxM8SMW/iYC+0kIi6E1d+fsvWk2Q0GnHw4EGkpaXZHU9LS8PevXsdviY3N7dV+fHjx+PAgQNoanL8W2R9fT2ampoQFhbmdr0AYDAYUF1dbfcgos7z1Jykag63EZGHyRaSKioqYDabER0dbXc8OjoaZWVlDl9TVlbmsLzJZEJFRYXD18ydOxd9+vTBuHHj3K4XALKyshASEmJ79Ovn+m+8RNSa51a3cbiNiDxL9onbCoXC7mshRKtjHZV3dBwAlixZgo0bN2Lr1q3Q6/WdqnfevHmoqqqyPc6ePdtmWSJyXuc3k+TEbSLyDnXHRbwjIiICKpWqVe9NeXl5q14eSUxMjMPyarUa4eHhdseXLl2KV199FZ9//jluuummTtULADqdDjqdzqn3RkTOsw23ub26Tdpxmz1JRORZsvUkabVaJCUlIScnx+54Tk4ORo0a5fA1KSkprcrv2LEDycnJ0Gg0tmOvv/46Xn75Zfz73/9GcnJyp+slIu+RepJ0ajdXt/mxJ4mIvEO2niQAyMzMxJQpU5CcnIyUlBS8/fbbKCoqQkZGBgDrEFdxcTE2bNgAwLqS7a233kJmZiYef/xx5ObmYu3atdi4caPtnEuWLMHzzz+PDz74APHx8bYeo8DAQAQGBjpVLxF1nQaj+ze4Ba7YAoA9SUTkYbKGpMmTJ6OyshKLFi1CaWkphg4diuzsbMTFxQEASktL7fYuSkhIQHZ2NmbPno0VK1YgNjYWb775JtLT021lVq5cCaPRiEmTJtnV9eKLL2LhwoVO1UtEXUeauM05SUTka2TdJ+laxn2SiDrPbBEYMD8bAHDo+bsQFqB1+RwX64wY/rJ1+PzHVyZArZJ9PQoR+bBrYp8kIiJpPhLQ+Z4kAKg1sDeJiDyHIYmIZNNwRUjSqd37ONKolLaAVd3AkEREnsOQRESykSZt69RKKJVt71PWkRA/6+TtKt6/jYg8iCGJiGRjMHVuZZuEIYmIvIEhiYhk02Ds3Mo2ibRXEkMSEXkSQxIRyUaak+TufdskUk8S90oiIk9iSCIi2TR6KCQFc7iNiLyAIYmIZGO7b5umcx9FnJNERN7AkEREsmls4sRtIvJdDElEJBvbcJubN7eVMCQRkTcwJBGRbKR9kvQe6kmqZkgiIg9iSCIi2TR08ua2EvYkEZE3MCQRkWxaVrd17qOIq9uIyBsYkohINraJ2+xJIiIfxJBERLJp8HBIqm5oghCi0+0iIgIYkohIRlJPks5DIckigFqDqdPtIiICGJKISEaemrit16igVVs/zjjkRkSewpBERLKRtgDo7GaSAOclEZHnMSQRkWwMJs+sbgMYkojI8xiSiEg2tp6kTg63AdxQkog8jyGJiGTTYNsnqfMhKVivBsCeJCLyHIYkIpKNJ0MSh9uIyNMYkohINgYPrW4Drhxu4xYAROQZDElEJBvbZpJc3UZEPoghiYhkI03c1qs9MCeJIYmIPIwhiYhkIYRAo7QFgJZbABCR72FIIiJZGEwWSLdZ48RtIvJFDElEJIv65qE2AAjQqjt9Pu6TRESexpBERLKoN1pXoenUSqiUik6fj3OSiMjTGJKISBZST5K/B1a2AfbDbUIaxyMi6gSGJCKSRUtI6vxQG9ASkkwWYdtagIioM9wKSQUFBZ5uBxH1MPUG63BbgM4zPUn+WhXUzcN2HHIjIk9wKyQNHDgQY8aMwT/+8Q80NjZ6uk1E1APUSTe39VBPkkKh4Ao3IvIot0LS999/j5/85Cd45plnEBMTgyeeeAL79+/3dNuIqBuTJm4HeGhOEnDFvKR6hiQi6jy3QtLQoUOxbNkyFBcXY/369SgrK8Ptt9+OIUOGYNmyZbhw4YKn20lE3YynJ24DXOFGRJ7VqYnbarUa999/Pz788EO89tprOHXqFObMmYO+ffti6tSpKC0t9VQ7iaib8fTEbaClJ+kyQxIReUCnQtKBAwfw5JNPonfv3li2bBnmzJmDU6dO4csvv0RxcTHuvfdeT7WTiLoZaeK2J3uSQv2bQ1K90WPnJKKey61f4ZYtW4b169fjxIkTmDhxIjZs2ICJEydCqbRmroSEBPztb3/DoEGDPNpYIuo+6ps835MUGqAFAFzinCQi8gC3Pp1WrVqFRx99FI888ghiYmIclunfvz/Wrl3bqcYRUffljZ6kMP/mkFTHniQi6jy3QlJOTg769+9v6zmSCCFw9uxZ9O/fH1qtFtOmTfNII4mo+5G2APD30D5JANCruSfpIkMSEXmAW3OSBgwYgIqKilbHL168iISEhE43ioi6v4bmkOSJm9tKpJ6kyxxuIyIPcCsktXVfpNraWuj1+k41iIh6hrrmfZL8PDlxO8A6cfsiJ24TkQe49CtcZmYmAOvOti+88AL8/f1tz5nNZuzbtw+33HKLRxtIRN1TvRd6kkJtPUkMSUTUeS59OuXl5QGw9iQdPXoUWq3W9pxWq8XNN9+MOXPmeLaFRNQtSTtue3Ti9hWr2ywWAWXzvdyIiNzhUkjauXMnAOCRRx7BG2+8geDgYK80ioi6P2/suN2reZ8ks0WgptGEkOaviYjc4dacpPXr1zMgEVGn1Bs8v0+STq2y3QvuEofciKiTnA5Jv/rVr1BdXW37e3sPV6xcuRIJCQnQ6/VISkrCnj172i2/e/duJCUlQa/XIzExEatXr7Z7/ocffkB6ejri4+OhUCiwfPnyVudYuHAhFAqF3aOt/Z6IyDukidue3AIAaNlQkpO3iaiznA5JISEhUCgUtr+393DW5s2bMWvWLCxYsAB5eXlITU3FhAkTUFRU5LB8QUEBJk6ciNTUVOTl5WH+/Pl4+umnsWXLFluZ+vp6JCYmYvHixe0GnyFDhqC0tNT2OHr0qNPtJqLOEUJ4ZQsAgJO3ichznP50Wr9+vcO/d8ayZcvw2GOPYcaMGQCA5cuXY/v27Vi1ahWysrJalV+9ejX69+9v6x0aPHgwDhw4gKVLlyI9PR0AcOutt+LWW28FAMydO7fNutVqNXuPiGRiNFtgsli3EvHkFgDAFT1JddwriYg6x605SQ0NDaivr7d9XVhYiOXLl2PHjh1On8NoNOLgwYNIS0uzO56Wloa9e/c6fE1ubm6r8uPHj8eBAwfQ1OTaB+LJkycRGxuLhIQEPPjggzh9+nS75Q0GA6qrq+0eROQeqRcJ8OzEbQAI401uichD3ApJ9957LzZs2AAAuHz5Mm677Tb8+c9/xr333otVq1Y5dY6KigqYzWZER0fbHY+OjkZZWZnD15SVlTksbzKZHO4A3pYRI0Zgw4YN2L59O9asWYOysjKMGjUKlZWVbb4mKyvLbkixX79+TtdHRPakW5JoVUpoVG59DLWplz9vTUJEnuHWp9OhQ4eQmpoKAPjoo48QExODwsJCbNiwAW+++aZL55LmOUmEEK2OdVTe0fH2TJgwAenp6Rg2bBjGjRuHTz/9FADw97//vc3XzJs3D1VVVbbH2bNnna6PiOzZbm7r4UnbwJV7JTEkEVHnuDVjsr6+HkFBQQCAHTt24Fe/+hWUSiVGjhyJwsJCp84REREBlUrVqteovLy8VW+RJCYmxmF5tVqN8PBwN96JVUBAAIYNG4aTJ0+2WUan00Gn07ldBxG1sO2RpPF8SAptHm5jTxIRdZZbPUkDBw7Exx9/jLNnz2L79u22eULl5eVO75+k1WqRlJSEnJwcu+M5OTkYNWqUw9ekpKS0Kr9jxw4kJydDo3F/0ziDwYD8/Hz07t3b7XMQkfNalv97dmUbAIQHWn+ZYUgios5yKyS98MILmDNnDuLj4zFixAikpKQAsAaWn/zkJ06fJzMzE++88w7WrVuH/Px8zJ49G0VFRcjIyABgHeKaOnWqrXxGRgYKCwuRmZmJ/Px8rFu3DmvXrrW7FYrRaMThw4dx+PBhGI1GFBcX4/Dhw/jxxx9tZebMmYPdu3ejoKAA+/btw6RJk1BdXY1p06a5czmIyEUty/8935MUGWQNSRdqDB4/NxH1LG79Gjdp0iTcfvvtKC0txc0332w7PnbsWNx///1On2fy5MmorKzEokWLUFpaiqFDhyI7OxtxcXEAgNLSUrs9kxISEpCdnY3Zs2djxYoViI2NxZtvvmlb/g8AJSUldkFt6dKlWLp0KUaPHo1du3YBAM6dO4eHHnoIFRUViIyMxMiRI/Htt9/a6iUi75Imbnt6+T8ARAYyJBGRZyiENPOZXFJdXY2QkBBUVVXxFi1ELtq0vwhztx7FnYOisG76rR49d53BhCEvbgcA/PDSeAR4YUiPiK5drvz8duvTo66uDosXL8YXX3yB8vJyWCwWu+c72nOIiHq22ubVbUF6zweYAJ0a/loV6o1mVNQaGJKIyG1ufXrMmDEDu3fvxpQpU9C7d2+Xlt8TEUkhKdBLASYySIfCynpcqDEgLjzAK3UQUffn1ifUZ599hk8//RQ//elPPd0eIuoBahqbQ5IXepIA67wkKSQREbnLrdVtoaGhCAsL83RbiKiHqG0OSUFe7EkCgAu1DElE5D63QtLLL7+MF154we7+bUREzuqK4TaAK9yIqHPc+oT685//jFOnTiE6Ohrx8fGtNnI8dOiQRxpHRN1TjRSS9O5vAtsebgNARJ7gVki67777PNwMIupJahubALAniYh8m1ufUC+++KKn20FEPYg3twAAOCeJiDzDrTlJAHD58mW88847mDdvHi5evAjAOsxWXFzsscYRUfckTdxmTxIR+TK3PqGOHDmCcePGISQkBGfOnMHjjz+OsLAwbNu2DYWFhdiwYYOn20lE3UjLnCTvhqSKWgMsFgGlknu5EZHr3OpJyszMxPTp03Hy5Eno9Xrb8QkTJuCrr77yWOOIqPsRQrQMt3mpJyk8QAeFAmgyC1yqN3qlDiLq/twKSd999x2eeOKJVsf79OmDsrKyTjeKiLqveqMZ0h0jvdWTpFUrbSvcSqsavVIHEXV/boUkvV6P6urqVsdPnDiByMjITjeKiLovqRdJpVTAT6PyWj29e/kBAIovN3itDiLq3twKSffeey8WLVqEpibrMl6FQoGioiLMnTsX6enpHm0gEXUvNVdM2vbmfR/79LJOBShhSCIiN7kVkpYuXYoLFy4gKioKDQ0NGD16NAYOHIigoCC88sornm4jEXUj3t5tWxIbYu1JYkgiIne59SkVHByMr7/+Gjt37sTBgwdhsVgwfPhwjBs3ztPtI6JupsbLG0lKYntJIYlzkojIPS5/SlksFrz77rvYunUrzpw5A4VCgYSEBMTExEAI4dXucyK69lU3WHuSgv26JiRxThIRucul4TYhBH75y19ixowZKC4uxrBhwzBkyBAUFhZi+vTpuP/++73VTiLqJqoarD1JIX7euW+bpE8vDrcRUee49Kvcu+++i6+++gpffPEFxowZY/fcl19+ifvuuw8bNmzA1KlTPdpIIuo+pJAU7O2QFGoNSeU1BjQ2maH34ko6IuqeXOpJ2rhxI+bPn98qIAHAnXfeiblz5+L999/3WOOIqPuRQlIvP61X6wn119juDVd0sd6rdRFR9+RSSDpy5AjuvvvuNp+fMGECvv/++043ioi6r6oG6w7Y3h5uUygUiA8PAAAUVNR5tS4i6p5cCkkXL15EdHR0m89HR0fj0qVLnW4UEXVfLXOSvDtxGwDiI6whqbCSIYmIXOdSSDKbzVCr2/5gU6lUMJlMnW4UEXVftuE2f+8OtwFAfLg/AKCggsNtROQ6l36VE0Jg+vTp0Ol0Dp83GAweaRQRdV9dtboNgG24jT1JROQOl0LStGnTOizDlW1E1J6uWt0GAPER1p6kM5yTRERucCkkrV+/3lvtIKIeoqq+63uSSqoauQ0AEbnMrXu3ERG5w2wRqGm+d1svf++HpLAALYJ03AaAiNzDkEREXaamsQlCWP/eFT1JCoXCtsKN2wAQkasYkoioy0jzkfy1KmhUXfPxI4UkzksiIlcxJBFRl7lcL+227f1eJEkCe5KIyE0MSUTUZS7WWXfbDgv0/h5JkkSGJCJyE0MSEXWZSikkBTjea80bOCeJiNzFkEREXaay1rrhbERA1/UkJTRvA1BeY0CtgXcEICLnMSQRUZexDbd1YUgK8dcgvLk+Tt4mIlcwJBFRl6mUYU4SwCE3InIPQxIRdRlpuC28C3uSAK5wIyL3MCQRUZeRhtvCu3DiNsCQRETuYUgioi5TUSvPcFv/MOuNbs9d4q1JiMh5DElE1GVaepK6NiT1CfUDAJRcbuzSeono2saQRERdot5oQkOTGQAQHti1w219ellDUll1I0xmS5fWTUTXLoYkIuoSlc1DbTq1EgFaVZfWHRmog0algNkicL7G0KV1E9G1iyGJiLrE+WrrUFd0sB4KhaJL61YqFegdYu1NKr7U0KV1E9G1iyGJiLrE+WprD050cNcOtUmkIbeSywxJROQchiQi6hJlzT1JUcF6WeqPbQ5JxQxJROQkhiQi6hLlzSEpRqaQ1KeXtV72JBGRsxiSiKhLtMxJkme4TerBKufEbSJykuwhaeXKlUhISIBer0dSUhL27NnTbvndu3cjKSkJer0eiYmJWL16td3zP/zwA9LT0xEfHw+FQoHly5d7pF4i6pyWOUny9CRFBlnD2QWGJCJykqwhafPmzZg1axYWLFiAvLw8pKamYsKECSgqKnJYvqCgABMnTkRqairy8vIwf/58PP3009iyZYutTH19PRITE7F48WLExMR4pF4i6rzzNc1zkoLkCUlRDElE5CKFEELIVfmIESMwfPhwrFq1ynZs8ODBuO+++5CVldWq/LPPPotPPvkE+fn5tmMZGRn4/vvvkZub26p8fHw8Zs2ahVmzZnWqXkeqq6sREhKCqqoqBAcHO/Uaop5s6IvbUWsw4ctnRiMxMrDL6z93qR63v7YTWpUSJ/50d5dvQ0BEvsGVn9+y9SQZjUYcPHgQaWlpdsfT0tKwd+9eh6/Jzc1tVX78+PE4cOAAmpqavFYvABgMBlRXV9s9iMg5tQYTag0mAPKtbpOG24xmC6oanPu8IKKeTbaQVFFRAbPZjOjoaLvj0dHRKCsrc/iasrIyh+VNJhMqKiq8Vi8AZGVlISQkxPbo16+fU/URUcvKtkCdGoE6tSxt0KlVCPHTAOCQGxE5R/aJ21d3eQsh2u0Gd1Te0XFP1ztv3jxUVVXZHmfPnnWpPqKeTJq0HSXTyjYJ5yURkSvk+ZUOQEREBFQqVavem/Ly8la9PJKYmBiH5dVqNcLDw71WLwDodDrodPJ+wBNdq8qbJ21HyzRpWxIZpMPJ8lpuA0BETpGtJ0mr1SIpKQk5OTl2x3NycjBq1CiHr0lJSWlVfseOHUhOToZGo/FavUTUOXLvkSSR5iVJoY2IqD2y9SQBQGZmJqZMmYLk5GSkpKTg7bffRlFRETIyMgBYh7iKi4uxYcMGANaVbG+99RYyMzPx+OOPIzc3F2vXrsXGjRtt5zQajTh+/Ljt78XFxTh8+DACAwMxcOBAp+olIs+Se48kSUSgNSRV1hllbQcRXRtkDUmTJ09GZWUlFi1ahNLSUgwdOhTZ2dmIi4sDAJSWltrtXZSQkIDs7GzMnj0bK1asQGxsLN58802kp6fbypSUlOAnP/mJ7eulS5di6dKlGD16NHbt2uVUvUTkWWW2niR5Q1JYgBYAcLGWIYmIOibrPknXMu6TROS8X6/ei+/OXMKK3wzHPTf1lq0dG/cXYd7Woxg3OArvTLtVtnYQkXyuiX2SiKjnaBluk3dOktSTxOE2InIGQxIReZUQ4oqJ2z4y3MaQREROYEgiIq+qbjDBYLIAaFldJheGJCJyBUMSEXmVdGPbXv4a6DUqWdsS5m8NSTWNJhibgxsRUVsYkojIq2xDbTJvJAkAIX4aKJs31r9cz94kImofQxIReZWv3JIEAJRKBUL9OXmbiJzDkEREXuUrk7Yl0rykSwxJRNQBhiQi8qpyH7kliSSU2wAQkZMYkojIq3zlliSScK5wIyInMSQRkVf5yi1JJKEMSUTkJIYkIvKqch8LSexJIiJnMSQRkddYLALlNb5xSxKJtLrtIrcAIKIOMCQRkddcrDfCZBFQKICIQN8ISeGBzSGpliGJiNrHkEREXiMt/w8P0EGj8o2PG9sWAOxJIqIO+ManFhF1S+XVvjXUBoCbSRKR0xiSiMhrfG0jSaBluO1SnRFCCJlbQ0S+jCGJiLzmvA/3JJksAtWNJplbQ0S+jCGJiLzmfI21JynKB25uK9FrVAjQqgBwGwAiah9DEhF5ja/tkSThhpJE5AyGJCLyGl8cbgO4oSQROYchiYi8xhcnbgMt2wBcrDPI3BIi8mUMSUTkFSazBRW1vnVzW0lYgLVnq4IbShJROxiSiMgrKmqNsAhApVTYhrd8RUQgh9uIqGMMSUTkFdJQW1SQDkqlQubW2AvjnCQicgJDEhF5hS0k+dhQG9ASkrjrNhG1hyGJiLzifE3zfKQg31rZBrTcbLeylhO3iahtDElE5BW+ukcSwOE2InIOQxIReUVZlRSSfK8n6crhNt6/jYjawpBERF5R2hySeof4ydyS1qSb3BpNFtQaeP82InKMIYmIvKLkcgMAILaX74Ukf60afhrev42I2seQREQeJ4RASZUUknxvThLAFW5E1DGGJCLyuEv1TWhssgAAYkJ8MyRJQ24Xues2EbWBIYmIPE4aaosI1EGnVsncGsfCbT1J3AaAiBxjSCIij2uZj+SbvUhAy/3bONxGRG1hSCIij5NWtsX64Mo2CYfbiKgjDElE5HHSpO3ePtyTFM6J20TUAYYkIvK4ksvWnqQ+Prj8XyLdmuRCDeckEZFjDElE5HGlzXOSfHEjSUlU807g5TWNMreEiHwVQxIReZw0cduXh9uigqxtK2dPEhG1gSGJiDzKaLKgrPnmtn19eLgtKsjak3S5vgkGk1nm1hCRL2JIIiKPKr7cAIsA/DQqRAb53s1tJb38NdCqrB+BnJdERI4wJBGRR52prAMAxIX7Q6FQyNyatikUCluI45AbETnCkEREHlVY0RKSfJ0tJFUzJBFRawxJRORRZyrrAQDx4QEyt6Rj0rykC1zhRkQOMCQRkUcVNg+39b8GepJatgFgTxIRtcaQREQeVdjckxQX5vs9SZGBzdsAcLiNiBxgSCIijzGYzCi8aA1JA6MCZW5Nx6SepAu1DElE1JrsIWnlypVISEiAXq9HUlIS9uzZ02753bt3IykpCXq9HomJiVi9enWrMlu2bMGNN94InU6HG2+8Edu2bbN7fuHChVAoFHaPmJgYj74vop6ooKIOZotAkF6N6GDfXf4viQrirttE1DZZQ9LmzZsxa9YsLFiwAHl5eUhNTcWECRNQVFTksHxBQQEmTpyI1NRU5OXlYf78+Xj66aexZcsWW5nc3FxMnjwZU6ZMwffff48pU6bggQcewL59++zONWTIEJSWltoeR48e9ep7JeoJ/nu+FgBwfXSQTy//l9h23eZwGxE5IGtIWrZsGR577DHMmDEDgwcPxvLly9GvXz+sWrXKYfnVq1ejf//+WL58OQYPHowZM2bg0UcfxdKlS21lli9fjrvuugvz5s3DoEGDMG/ePIwdOxbLly+3O5darUZMTIztERkZ2W5bDQYDqqur7R5EZO/H8zUAgOuugaE2oGW4raLWAJPZInNriMjXyBaSjEYjDh48iLS0NLvjaWlp2Lt3r8PX5Obmtio/fvx4HDhwAE1NTe2WufqcJ0+eRGxsLBISEvDggw/i9OnT7bY3KysLISEhtke/fv2cep9EPYnUk3RddJDMLXFORKAOaqUCFsF5SUTUmmwhqaKiAmazGdHR0XbHo6OjUVZW5vA1ZWVlDsubTCZUVFS0W+bKc44YMQIbNmzA9u3bsWbNGpSVlWHUqFGorKxss73z5s1DVVWV7XH27FmX3i9RT/CfMmsP6w3XSEhSKRWIDrYOuZVc5rwkIrKnlrsBV89bEEK0O5fBUfmrj3d0zgkTJtj+PmzYMKSkpGDAgAH4+9//jszMTIf16nQ66HS+PxGVSC7VjU22jSSH9gmWuTXOiwnRo/hyA8qqGJKIyJ5sPUkRERFQqVSteo3Ky8tb9QRJYmJiHJZXq9UIDw9vt0xb5wSAgIAADBs2DCdPnnTnrRARgB+Krb1IfUP90MtfK3NrnNc7xNqTVFrVIHNLiMjXyBaStFotkpKSkJOTY3c8JycHo0aNcvialJSUVuV37NiB5ORkaDSadsu0dU7AOik7Pz8fvXv3duetEBGAY8VVAIChsSEyt8Q1sb38AHC4jYhak3V1W2ZmJt555x2sW7cO+fn5mD17NoqKipCRkQHAOg9o6tSptvIZGRkoLCxEZmYm8vPzsW7dOqxduxZz5syxlfnjH/+IHTt24LXXXsN//vMfvPbaa/j8888xa9YsW5k5c+Zg9+7dKCgowL59+zBp0iRUV1dj2rRpXfbeibqbo80haUjstTPUBrAniYjaJuucpMmTJ6OyshKLFi1CaWkphg4diuzsbMTFxQEASktL7fZMSkhIQHZ2NmbPno0VK1YgNjYWb775JtLT021lRo0ahU2bNuG5557D888/jwEDBmDz5s0YMWKErcy5c+fw0EMPoaKiApGRkRg5ciS+/fZbW71E5LqDhZcAAD/pHypzS1zTO8Tak1TKOUlEdBWFkGY+k0uqq6sREhKCqqoqBAdfW785E3laWVUjRmZ9AaUCOLJwPAJ1sq8JcdqRc5fxy7e+QXSwDvvmj5O7OUTkZa78/Jb9tiREdO07UHgRADC4d/A1FZAA6+o2ACivMaCJG0oS0RUYkoio0w6csQ61JcddW0NtABARoINGpYAQwPlqDrkRUQuGJCLqtD0nLwAAUgZEyNwS1ymVCltvEvdKIqIrMSQRUacUX27AqQt1UCkVSBkQLndz3CJN3i5hSCKiKzAkEVGnfPVfay/SLf16IcRPI3Nr3BMrbQNwmdsAEFELhiQi6pTPjll3uB9zQ6TMLXFf717cBoCIWmNIIiK3Xaoz4psfrTeXnjjs2t2xnhtKEpEjDElE5Lb/O1ICs0Xgxt7BSIwMlLs5brPNSeKtSYjoCgxJROQWIQQ25BYCAH6d3Ffm1nRO31BrSDp3qV7mlhCRL2FIIiK3fPNjJX4sr0WAVoVJSd0jJF2qb0KtwSRza4jIVzAkEZFb3t17BgCQntQXQfprc1WbJEivQS9/63s4e5G9SURkxZBERC47d6keX/znPABgakq8vI3xkH6h/gAYkoioBUMSEbls0/6zEAL46cBwDIy6didsX6lfmHXI7ewlrnAjIiuGJCJySZPZgs0HzgIAfjsiTubWeI7Uk8TJ20QkYUgiIpd8fvw8LtQYEBGow103RsvdHI/pGyYNt7EniYisGJKIyCUf7C8CADyQ3BcaVff5COnHbQCI6Crd5xOOiLyusLIOe05WQKEAHrqtv9zN8ah+YS0Tt4UQMreGiHwBQxIROW3jfutcpNTrIm2horvo03z/tjqjGZfqm2RuDRH5AoYkInKK0WTBRwetIek33awXCQD0GhVigq33cCuoqJO5NUTkCxiSiMgpO46XoaLWiOhgHcYOjpK7OV4xICoAAHDqQq3MLSEiX8CQREROef9b64Ttycn9utWE7SsNbL5JL0MSEQEMSUTkhFMXapF7uhJKBTC5Gw61SQY0b4x5qpwhiYgYkojICeu+LgAA3DkoyjbBuTtq6UninCQiYkgiog5cqDFgy6FzAIDHbk+UuTXeJfUkFVbWwWAyy9waIpIbQxIRtWvp9hNobLLg5n69MDIxTO7meFVUkA5BOjUsAiis5KaSRD0dQxIRtWnHD2W2+7S98PMboVAoZG6RdykUCiQ29yb9yHlJRD0eQxIROfTlf87jqY15AIDpo+KRFBcqc4u6hjQv6eR5hiSink4tdwOIyPf883AxMj/8HmaLwJ2DorDgnsFyN6nLDO4dBAD4oaRK5pYQkdwYkojIzv8eOIv/2XIEQgD33RKL1399c7fdF8mRoX1CAADHihmSiHq6nvPJR0Qdyiu6hPnbjkIIYGpKHJY9cEuPCkgAMCQ2GABQUtWIylqDzK0hIjn1rE8/ImqTyWzB3C1H0WQWuHtIDF765RAold17orYjQXoNEiOstyc5yt4koh6NIYmIAAAbcgtx4nwNevlrkPWrYd1+JVt7buprHXLLK7osb0OISFYMSUSE8ppG/CXnvwCA/xk/CKEBWplbJK/keOt+UN+duShzS4hITgxJRITF2f9BjcGEm/qGYPKt/eRujuxGJFhD0qGiSzCaLDK3hojkwpBE1MPtOlGOrXnFUCiARfcOhaoHzkO62sCoQIT6a9DYZOG8JKIejCGJqAe7XG/Egm3HAFg3jLylXy95G+QjFAoFRiaGAwD2nLwgc2uISC4MSUQ91KU6I3634SCKLzegX5gf/t/4G+Rukk8Zc0MUAGDnCYYkop6Km0kS9UCHii5h5vuHUFLViECdGmumJsNfy4+DK91xQyQA4Mi5y7hQY0BkkE7mFhFRV2NPElEPIoTA2q8L8MDqXJRUNSI+3B+bnxiJQTHBcjfN50QF63Fz3xAIAXx6pETu5hCRDBiSiHoIIQT+9Gk+Xv7XcZgsAvfc1Bv/99TtGBIbInfTfNZ9P+kDANhyqFjmlhCRHBiSiHoAi0XguY+PYe3XBQCA5+4ZjLce+gmC9BqZW+bb7r2lDzQqBY4WV+FQ0SW5m0NEXYwhiaibM5osmPO/3+P9fUVQKIAl6TdhRmpij95R21lhAVrcd4u1N2nZjv9CCCFzi4ioKzEkEXVjxZcb8PDafdiaVwyVUoHlk2/BA9ws0iVP3Xkd1EoFvv6xAtvyOOxG1JMwJBF1QyazBe/sOY27lu3G/oKLCNSp8c60ZNzb3CtCzusf7o8/jr0OALBg2zEc4K1KiHoMhiSibia/tBq/WrUXf/o0H/VGM26ND8XHf/ipbd8fct3v7xiA0ddHoqHJjEfWf4fcU5VyN4mIugBDElE30dhkxuvb/4Nf/PVrHDlXhSC9Glm/GobNv0vBwKhAuZt3TVOrlFj9cBJuSwhDjcGEKWv34W+7T8Fk5n3diLoz2UPSypUrkZCQAL1ej6SkJOzZs6fd8rt370ZSUhL0ej0SExOxevXqVmW2bNmCG2+8ETqdDjfeeCO2bdvW6XqJfNnu/17AxDf2YMXOUzBZBO4eEoMvMkfjodv6Q8l7sXmEn1aFDY/ehl/cHAuTRSDrs/8gbflXePurUzhy7jJvhEvUDcm6xe7mzZsxa9YsrFy5Ej/96U/xt7/9DRMmTMDx48fRv3//VuULCgowceJEPP744/jHP/6Bb775Bk8++SQiIyORnp4OAMjNzcXkyZPx8ssv4/7778e2bdvwwAMP4Ouvv8aIESPcqpfIVwghUGc0o7LWgB/La/FDSTW2/1CGH0qqAQBRQTosuncI7h7aW+aWdk96jQpvPngLUgdG4JXsfJy+UIdXs/8DAFApFegf5o/EiAAkRgYgMTIQ8eEBCAvQIlCvRqDO+uANhImuHQoh45rWESNGYPjw4Vi1apXt2ODBg3HfffchKyurVflnn30Wn3zyCfLz823HMjIy8P333yM3NxcAMHnyZFRXV+Ozzz6zlbn77rsRGhqKjRs3ulUvABgMBhgMBtvX1dXV6NevH6qqqhAc7Lndio8VV+Gjg+fafP7qf66r//Gu/tcUV5Vo/Xz7r29dwsE5PFzn1a/v4Es3rolrr29df/vvDwCUSgXUSgVUSgVUCgWUCgWUSgWkn48WYa3XIgQswrqPke3vQkAIwGSxwGwRMJgsuFRvRGWtEZV1Roc9FlqVElNS4vDHcdchmHsfdYmaxib883AJco6fx/fnLuNyfZNTrwvQqlpCk16DYL0aOrUSSoX1+0Vp+56B7e/ScaUCUCkUUCgUaDJbYDILNFmsf5osFjQ2WVBvNKGhyQKlwvp9oVUroVEpoVUpoVZZX1dvNKOxyYwms4BOrYROo7L+qVZCp1ZBp7GWv5L0/0TYvm7+s/lIy9f2z+OK5519je3/WKvn22qD/fMSaZsL6f/ilX+yh/XaMDQ2BOlJfT16zurqaoSEhDj181u2niSj0YiDBw9i7ty5dsfT0tKwd+9eh6/Jzc1FWlqa3bHx48dj7dq1aGpqgkajQW5uLmbPnt2qzPLly92uFwCysrLw0ksvOfv23Ha6og7v7j3j9Xro2qZTK9E/zB9D+4RgeP9euOemWIQFaOVuVo8SpNfg4ZFxeHhkHIQQOF9twOkLtThVUYfTF2px+kIdii7Wo7qhCTWNJhib5y/VGc2oM5pxHoYOaiCiX94c6/GQ5ArZQlJFRQXMZjOio6PtjkdHR6OsrMzha8rKyhyWN5lMqKioQO/evdssI53TnXoBYN68ecjMzLR9LfUkedp1UYGYOWag3bGr9/xr9fvPVQWufr716xUdPN/+663H2v8tzNN1dvT6jtrX8fk7eL0r/wbNPUImi4DJbLH1DlksAmYhoEBLL4FCAWsvk+1P698Vzb0HGpUCaqUSoQEahAXoEB6gRXigljej9TEKhQIxIXrEhOgxamCEwzIGkxm1jSbUNJpQa7D+WdPYEqDMUm+iRcB8Re+iWTpmaf4+au5pVKsU0KiUUCsVUDf/6adRwU+rgl6jAmDdSLTJbIHRZIHRbP27Vq20ltOooFIq0GQWMJjMMJgsMDQ1/2my2PVYSt/eiqsOKFo9r3BY3vZ1G/+vrvz/3eZrrzr3ldfeUfkre5ksFgGTRcBssTT/vxSte6zJJ8l9X0nZP2mv/k8jhGj3B7Cj8lcfd+acrtar0+mg03n/LuCDewdjcG/ebJSou9GpVdAFqhAe6P3PESLyDNlWt0VEREClUrXqvSkvL2/VyyOJiYlxWF6tViM8PLzdMtI53amXiIiIeh7ZQpJWq0VSUhJycnLsjufk5GDUqFEOX5OSktKq/I4dO5CcnAyNRtNuGemc7tRLREREPZCQ0aZNm4RGoxFr164Vx48fF7NmzRIBAQHizJkzQggh5s6dK6ZMmWIrf/r0aeHv7y9mz54tjh8/LtauXSs0Go346KOPbGW++eYboVKpxOLFi0V+fr5YvHixUKvV4ttvv3W6XmdUVVUJAKKqqsoDV4KIiIi6gis/v2WdkzR58mRUVlZi0aJFKC0txdChQ5GdnY24uDgAQGlpKYqKimzlExISkJ2djdmzZ2PFihWIjY3Fm2++adsjCQBGjRqFTZs24bnnnsPzzz+PAQMGYPPmzbY9kpypl4iIiEjWfZKuZa7ss0BERES+wZWf37LfloSIiIjIFzEkERERETnAkERERETkAEMSERERkQMMSUREREQOMCQREREROcCQREREROQAQxIRERGRA7LuuH0tk/bgrK6ulrklRERE5Czp57Yze2kzJLmppqYGANCvXz+ZW0JERESuqqmpQUhISLtleFsSN1ksFpSUlCAoKAgKhULu5nRadXU1+vXrh7Nnz/I2Kx7A6+k5vJaew2vpWbyentOV11IIgZqaGsTGxkKpbH/WEXuS3KRUKtG3b1+5m+FxwcHB/M/uQbyensNr6Tm8lp7F6+k5XXUtO+pBknDiNhEREZEDDElEREREDjAkEQBAp9PhxRdfhE6nk7sp3QKvp+fwWnoOr6Vn8Xp6jq9eS07cJiIiInKAPUlEREREDjAkERERETnAkERERETkAEMSERERkQMMSUREREQOMCT1IGfOnMFjjz2GhIQE+Pn5YcCAAXjxxRdhNBrtyhUVFeEXv/gFAgICEBERgaeffrpVmaNHj2L06NHw8/NDnz59sGjRIqduFtjdvPLKKxg1ahT8/f3Rq1cvh2V4Pd23cuVKJCQkQK/XIykpCXv27JG7ST7pq6++wi9+8QvExsZCoVDg448/tnteCIGFCxciNjYWfn5+uOOOO/DDDz/YlTEYDHjqqacQERGBgIAA/PKXv8S5c+e68F3ILysrC7feeiuCgoIQFRWF++67DydOnLArw2vpvFWrVuGmm26y7aKdkpKCzz77zPb8NXEtBfUYn332mZg+fbrYvn27OHXqlPjnP/8poqKixDPPPGMrYzKZxNChQ8WYMWPEoUOHRE5OjoiNjRUzZ860lamqqhLR0dHiwQcfFEePHhVbtmwRQUFBYunSpXK8LVm98MILYtmyZSIzM1OEhIS0ep7X032bNm0SGo1GrFmzRhw/flz88Y9/FAEBAaKwsFDupvmc7OxssWDBArFlyxYBQGzbts3u+cWLF4ugoCCxZcsWcfToUTF58mTRu3dvUV1dbSuTkZEh+vTpI3JycsShQ4fEmDFjxM033yxMJlMXvxv5jB8/Xqxfv14cO3ZMHD58WNxzzz2if//+ora21laG19J5n3zyifj000/FiRMnxIkTJ8T8+fOFRqMRx44dE0JcG9eSIamHW7JkiUhISLB9nZ2dLZRKpSguLrYd27hxo9DpdKKqqkoIIcTKlStFSEiIaGxstJXJysoSsbGxwmKxdF3jfcj69esdhiReT/fddtttIiMjw+7YoEGDxNy5c2Vq0bXh6pBksVhETEyMWLx4se1YY2OjCAkJEatXrxZCCHH58mWh0WjEpk2bbGWKi4uFUqkU//73v7us7b6mvLxcABC7d+8WQvBaekJoaKh45513rplryeG2Hq6qqgphYWG2r3NzczF06FDExsbajo0fPx4GgwEHDx60lRk9erTdzqjjx49HSUkJzpw502VtvxbwerrHaDTi4MGDSEtLszuelpaGvXv3ytSqa1NBQQHKysrsrqVOp8Po0aNt1/LgwYNoamqyKxMbG4uhQ4f26OtdVVUFALbPSF5L95nNZmzatAl1dXVISUm5Zq4lQ1IPdurUKfz1r39FRkaG7VhZWRmio6PtyoWGhkKr1aKsrKzNMtLXUhmy4vV0T0VFBcxms8Pr0lOvibuk69XetSwrK4NWq0VoaGibZXoaIQQyMzNx++23Y+jQoQB4Ld1x9OhRBAYGQqfTISMjA9u2bcONN954zVxLhqRuYOHChVAoFO0+Dhw4YPeakpIS3H333fj1r3+NGTNm2D2nUCha1SGEsDt+dRnRPMnY0WuvNe5cz/b09OvZGY6uS0+/Ju5y51r25Os9c+ZMHDlyBBs3bmz1HK+l82644QYcPnwY3377LX7/+99j2rRpOH78uO15X7+W6i6phbxq5syZePDBB9stEx8fb/t7SUkJxowZg5SUFLz99tt25WJiYrBv3z67Y5cuXUJTU5Mt8cfExLRK8eXl5QBa/1ZwLXL1eraH19M9ERERUKlUDq9LT70m7oqJiQFg/a28d+/etuNXXsuYmBgYjUZcunTJ7rf28vJyjBo1qmsb7AOeeuopfPLJJ/jqq6/Qt29f23FeS9dptVoMHDgQAJCcnIzvvvsOb7zxBp599lkAvn8t2ZPUDURERGDQoEHtPvR6PQCguLgYd9xxB4YPH47169dDqbT/FkhJScGxY8dQWlpqO7Zjxw7odDokJSXZynz11Vd2y9h37NiB2NhYp8ODL3PlenaE19M9Wq0WSUlJyMnJsTuek5PTI3/QdEZCQgJiYmLsrqXRaMTu3btt1zIpKQkajcauTGlpKY4dO9ajrrcQAjNnzsTWrVvx5ZdfIiEhwe55XsvOE0LAYDBcO9eyS6aHk08oLi4WAwcOFHfeeac4d+6cKC0ttT0k0pL1sWPHikOHDonPP/9c9O3b127J+uXLl0V0dLR46KGHxNGjR8XWrVtFcHBwj1yyXlhYKPLy8sRLL70kAgMDRV5ensjLyxM1NTVCCF7PzpC2AFi7dq04fvy4mDVrlggICBBnzpyRu2k+p6amxva9B0AsW7ZM5OXl2bZLWLx4sQgJCRFbt24VR48eFQ899JDDpdZ9+/YVn3/+uTh06JC48847e9yy9d///vciJCRE7Nq1y+7zsb6+3laG19J58+bNE1999ZUoKCgQR44cEfPnzxdKpVLs2LFDCHFtXEuGpB5k/fr1AoDDx5UKCwvFPffcI/z8/ERYWJiYOXOm3fJ0IYQ4cuSISE1NFTqdTsTExIiFCxf2yOXq06ZNc3g9d+7caSvD6+m+FStWiLi4OKHVasXw4cNtS7HJ3s6dOx1+H06bNk0IYV26/uKLL4qYmBih0+nEz372M3H06FG7czQ0NIiZM2eKsLAw4efnJ37+85+LoqIiGd6NfNr6fFy/fr2tDK+l8x599FHb/9/IyEgxduxYW0AS4tq4lgohuK0vERER0dU4J4mIiIjIAYYkIiIiIgcYkoiIiIgcYEgiIiIicoAhiYiIiMgBhiQiIiIiBxiSiIiIiBxgSCIiIiJygCGJiIiIyAGGJCIiIiIHGJKIiIiIHPj/d1vDyBRCCvEAAAAASUVORK5CYII=\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jarque-Bera Wald Test for Normality\n",
      "Skewness of Residuals =  -0.4585474348889915\n",
      "Kurtosis of Residuals =  5.161716495966431\n",
      "Chi-Sq( 2)     3671.459072\n",
      "Prob>Chi-Sq       0.000000\n",
      "dtype: float64\n",
      "Residuals have not normal distribution\n",
      "\n",
      "count    15980.000000\n",
      "mean         0.003206\n",
      "std         16.628200\n",
      "min       -100.090317\n",
      "25%         -8.247744\n",
      "50%          0.591089\n",
      "75%         10.328437\n",
      "max        170.165555\n",
      "dtype: float64\n",
      "\n",
      "Goldfeld-Quandt test:\n",
      "F(14,14)    0.933265\n",
      "Prob>F      0.998877\n",
      "dtype: float64\n",
      "\n",
      "Goldfeld-Quandt test: There isn't Heteroscedasticity in residuals\n",
      "\n",
      "Durbin-Watson test for AR(1):\n",
      "dw_statistic: 1.9653281017251243\n",
      "1.5 <= dw_statistic <= 2.5\n",
      "There isn't autocorrelation in residuals\n"
     ]
    }
   ],
   "source": [
    "residuals = regressor_OLS.resid\n",
    "resid_normality_analisis(residuals)\n",
    "print()\n",
    "resid_het_analisis(X_train, y_train)\n",
    "print()\n",
    "resid_autocorr_analisis(residuals)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SymbolicRegressor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0     8.12           785857        3          1013.67          1057.58      3.43m\n",
      "   1    11.02          8272.72        3          1010.01          1090.49      4.09m\n",
      "   2    15.99           215227        4          808.354          800.829      4.85m\n",
      "   3    14.46      2.21653e+06        8          568.509          602.851      4.46m\n",
      "   4    11.54           441837        8          568.869          599.608      3.54m\n",
      "   5    17.35      3.00817e+07        8           568.49          603.021      4.98m\n",
      "   6    18.59      1.19231e+07       22          542.228          534.709      5.13m\n",
      "   7    16.77      1.33531e+06        8          539.247          571.694      5.74m\n",
      "   8    11.07           142199       22          536.359           587.53      4.52m\n",
      "   9    11.90          78316.7       22          508.789          527.298      6.44m\n",
      "  10    15.45           133370       22           491.22          512.602      5.18m\n",
      "  11    23.14           134386       20          470.192          500.484      6.84m\n",
      "  12    25.26           110010       20          470.145          500.911      5.75m\n",
      "  13    23.80           176447       36          465.828           436.94      3.21m\n",
      "  14    24.82           129593       17          440.268          462.101      4.34m\n",
      "  15    25.91           112937       23          436.178          434.521      2.55m\n",
      "  16    26.69           131091       16          426.397          427.682      1.99m\n",
      "  17    28.25           138065       66          409.348          420.233      2.09m\n",
      "  18    25.79           181795       47          400.118          378.409     50.36s\n",
      "  19    27.52           254567       41           396.51          411.318      0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": "SymbolicRegressor(function_set=('add', 'sub', 'mul', 'div', 'sin', 'cos', 'tan',\n                                'log', 'sqrt'),\n                  max_samples=0.9, metric='mse', p_crossover=0.7,\n                  p_hoist_mutation=0.05, p_point_mutation=0.1,\n                  p_subtree_mutation=0.1, parsimony_coefficient=0.01,\n                  population_size=5000, random_state=0, stopping_criteria=0.01,\n                  verbose=1)",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>mul(sqrt(X7), add(mul(sqrt(cos(div(X137, X71))), add(mul(mul(sqrt(add(sqrt(X91), tan(X6))), add(mul(tan(tan(cos(div(X137, X71)))), X70), tan(tan(cos(X74))))), X70), tan(tan(cos(X74))))), tan(tan(cos(X74)))))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SymbolicRegressor</label><div class=\"sk-toggleable__content\"><pre>mul(sqrt(X7), add(mul(sqrt(cos(div(X137, X71))), add(mul(mul(sqrt(add(sqrt(X91), tan(X6))), add(mul(tan(tan(cos(div(X137, X71)))), X70), tan(tan(cos(X74))))), X70), tan(tan(cos(X74))))), tan(tan(cos(X74)))))</pre></div></div></div></div></div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gplearn.genetic import SymbolicRegressor\n",
    "est_gp = SymbolicRegressor(population_size=5000,\n",
    "                           function_set=('add', 'sub', 'mul','div','sin','cos','tan','log','sqrt'),\n",
    "                           metric=\"mse\",\n",
    "                           generations=20, stopping_criteria=0.01,\n",
    "                           p_crossover=0.7, p_subtree_mutation=0.1,\n",
    "                           p_hoist_mutation=0.05, p_point_mutation=0.1,\n",
    "                           max_samples=0.9, verbose=1,\n",
    "                           parsimony_coefficient=0.01, random_state=0)\n",
    "est_gp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 14.065\n",
      "Mean Squared Error: 372.909\n",
      "Root Mean Squared Error: 19.311\n",
      "Mean absolute percentage error: 196.062\n",
      "Scaled Mean absolute percentage error: 64.46\n",
      "r2_score: 0.689\n"
     ]
    }
   ],
   "source": [
    "metrics_eval(y_val, est_gp.predict(X_val));"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Neural network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 13:27:55.085026: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-12 13:28:16.435869: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "400/400 [==============================] - 4s 6ms/step - loss: 16.4692 - mse: 599.1985 - val_loss: 11.3664 - val_mse: 292.8014\n",
      "Epoch 2/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 12.4157 - mse: 350.9258 - val_loss: 10.9485 - val_mse: 291.8219\n",
      "Epoch 3/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 11.7623 - mse: 327.2812 - val_loss: 10.4912 - val_mse: 267.7072\n",
      "Epoch 4/200\n",
      "400/400 [==============================] - 2s 6ms/step - loss: 11.5319 - mse: 318.1928 - val_loss: 10.5006 - val_mse: 248.9657\n",
      "Epoch 5/200\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 11.3108 - mse: 308.8976 - val_loss: 14.1598 - val_mse: 422.7380\n",
      "Epoch 6/200\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 11.1745 - mse: 302.3345 - val_loss: 10.4269 - val_mse: 288.7351\n",
      "Epoch 7/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 11.0236 - mse: 294.5442 - val_loss: 9.8773 - val_mse: 234.7916\n",
      "Epoch 8/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 10.8914 - mse: 289.6450 - val_loss: 10.0969 - val_mse: 266.3139\n",
      "Epoch 9/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 10.8608 - mse: 285.0815 - val_loss: 9.7154 - val_mse: 236.5791\n",
      "Epoch 10/200\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 10.6616 - mse: 276.9289 - val_loss: 12.1390 - val_mse: 320.4304\n",
      "Epoch 11/200\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 10.5940 - mse: 272.0488 - val_loss: 9.4170 - val_mse: 224.7257\n",
      "Epoch 12/200\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 10.4917 - mse: 271.2170 - val_loss: 9.4263 - val_mse: 213.6608\n",
      "Epoch 13/200\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 10.4076 - mse: 268.7544 - val_loss: 9.7598 - val_mse: 213.4563\n",
      "Epoch 14/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 10.3037 - mse: 264.6363 - val_loss: 9.4484 - val_mse: 206.9465\n",
      "Epoch 15/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 10.2723 - mse: 265.8937 - val_loss: 9.1282 - val_mse: 207.3416\n",
      "Epoch 16/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 10.1507 - mse: 259.8126 - val_loss: 10.8150 - val_mse: 256.0883\n",
      "Epoch 17/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 10.0519 - mse: 253.7257 - val_loss: 9.0098 - val_mse: 211.9840\n",
      "Epoch 18/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 10.1140 - mse: 257.0070 - val_loss: 8.9206 - val_mse: 219.0023\n",
      "Epoch 19/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 9.9717 - mse: 253.2329 - val_loss: 8.8472 - val_mse: 203.7008\n",
      "Epoch 20/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 9.9494 - mse: 252.3893 - val_loss: 9.2274 - val_mse: 204.9810\n",
      "Epoch 21/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 9.9887 - mse: 252.9509 - val_loss: 8.8298 - val_mse: 198.5523\n",
      "Epoch 22/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 9.8833 - mse: 246.0590 - val_loss: 8.7602 - val_mse: 200.6515\n",
      "Epoch 23/200\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 9.8653 - mse: 250.2823 - val_loss: 9.0470 - val_mse: 196.1724\n",
      "Epoch 24/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 9.7931 - mse: 246.2534 - val_loss: 8.6427 - val_mse: 203.8941\n",
      "Epoch 25/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 9.7385 - mse: 244.1814 - val_loss: 9.0638 - val_mse: 242.8433\n",
      "Epoch 26/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 9.7285 - mse: 241.9237 - val_loss: 8.7816 - val_mse: 192.4990\n",
      "Epoch 27/200\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 9.8352 - mse: 247.8801 - val_loss: 9.7300 - val_mse: 220.2398\n",
      "Epoch 28/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 9.6629 - mse: 239.3443 - val_loss: 8.8319 - val_mse: 190.4652\n",
      "Epoch 29/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 9.7508 - mse: 242.9659 - val_loss: 8.5217 - val_mse: 190.3140\n",
      "Epoch 30/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 9.6995 - mse: 242.4161 - val_loss: 8.6049 - val_mse: 193.5967\n",
      "Epoch 31/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 9.5999 - mse: 235.5352 - val_loss: 8.9758 - val_mse: 196.4876\n",
      "Epoch 32/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 9.5022 - mse: 232.5794 - val_loss: 8.7330 - val_mse: 193.9556\n",
      "Epoch 33/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 9.5351 - mse: 238.3148 - val_loss: 8.4977 - val_mse: 187.6530\n",
      "Epoch 34/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 9.6118 - mse: 241.4323 - val_loss: 8.4995 - val_mse: 184.4056\n",
      "Epoch 35/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 9.5211 - mse: 233.0276 - val_loss: 8.7167 - val_mse: 203.4056\n",
      "Epoch 36/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 9.4251 - mse: 232.2035 - val_loss: 9.1212 - val_mse: 195.1039\n",
      "Epoch 37/200\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 9.5220 - mse: 235.1258 - val_loss: 8.7789 - val_mse: 214.6491\n",
      "Epoch 38/200\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 9.5237 - mse: 234.4633 - val_loss: 8.5606 - val_mse: 206.9627\n",
      "Epoch 39/200\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 9.4933 - mse: 235.5571 - val_loss: 8.6381 - val_mse: 183.8943\n",
      "Epoch 40/200\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 9.3397 - mse: 228.1887 - val_loss: 9.0890 - val_mse: 196.9583\n",
      "Epoch 41/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 9.5773 - mse: 236.6498 - val_loss: 9.0612 - val_mse: 194.5831\n",
      "Epoch 42/200\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 9.4221 - mse: 232.1075 - val_loss: 8.3823 - val_mse: 192.1317\n",
      "Epoch 43/200\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 9.3379 - mse: 227.8973 - val_loss: 8.6723 - val_mse: 184.1541\n",
      "Epoch 44/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 9.3637 - mse: 228.5588 - val_loss: 8.9970 - val_mse: 194.0785\n",
      "Epoch 45/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 9.1378 - mse: 218.6081 - val_loss: 8.4504 - val_mse: 179.3387\n",
      "Epoch 46/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 9.3401 - mse: 229.0941 - val_loss: 9.4756 - val_mse: 252.5736\n",
      "Epoch 47/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 9.2667 - mse: 224.1716 - val_loss: 9.0859 - val_mse: 192.0157\n",
      "Epoch 48/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 9.2528 - mse: 223.8680 - val_loss: 8.9406 - val_mse: 186.9433\n",
      "Epoch 49/200\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 9.1895 - mse: 222.5158 - val_loss: 8.3810 - val_mse: 171.9886\n",
      "Epoch 50/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 9.1790 - mse: 221.7836 - val_loss: 8.1491 - val_mse: 179.1334\n",
      "Epoch 51/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 9.1519 - mse: 219.8763 - val_loss: 8.1755 - val_mse: 170.3255\n",
      "Epoch 52/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 9.0288 - mse: 214.9042 - val_loss: 8.1744 - val_mse: 175.6228\n",
      "Epoch 53/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 9.1104 - mse: 218.5325 - val_loss: 8.2677 - val_mse: 169.0983\n",
      "Epoch 54/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 9.0296 - mse: 212.8346 - val_loss: 8.6959 - val_mse: 184.3261\n",
      "Epoch 55/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 9.0422 - mse: 213.2761 - val_loss: 8.4499 - val_mse: 200.5789\n",
      "Epoch 56/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 9.0178 - mse: 214.4249 - val_loss: 8.0354 - val_mse: 174.5972\n",
      "Epoch 57/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 9.0415 - mse: 215.7959 - val_loss: 8.2384 - val_mse: 171.1417\n",
      "Epoch 58/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 8.9644 - mse: 212.5049 - val_loss: 8.6299 - val_mse: 183.4723\n",
      "Epoch 59/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 8.9438 - mse: 209.5649 - val_loss: 8.0963 - val_mse: 167.1820\n",
      "Epoch 60/200\n",
      "400/400 [==============================] - 1s 4ms/step - loss: 8.9692 - mse: 214.9785 - val_loss: 8.0544 - val_mse: 169.8917\n",
      "Epoch 61/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 8.9056 - mse: 211.7140 - val_loss: 8.1056 - val_mse: 179.7550\n",
      "Epoch 62/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 8.9773 - mse: 211.1861 - val_loss: 8.7261 - val_mse: 181.8265\n",
      "Epoch 63/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 8.9888 - mse: 212.6463 - val_loss: 9.0654 - val_mse: 235.6718\n",
      "Epoch 64/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 9.0062 - mse: 213.1749 - val_loss: 8.0757 - val_mse: 169.9347\n",
      "Epoch 65/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 8.8645 - mse: 207.6777 - val_loss: 8.3219 - val_mse: 169.5852\n",
      "Epoch 66/200\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 8.9153 - mse: 211.2220 - val_loss: 9.2570 - val_mse: 250.6852\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "my_callbacks = [keras.callbacks.EarlyStopping(patience=10),\n",
    "                keras.callbacks.ModelCheckpoint(\n",
    "                    filepath='models/best_model.h5',\n",
    "                    monitor='val_loss',\n",
    "                    save_weights_only=True,\n",
    "                    mode='auto',\n",
    "                    save_best_only=True)\n",
    "]\n",
    "\n",
    "nn_model = keras.Sequential([\n",
    "    keras.layers.Dense(32, input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(128,\n",
    "#                        kernel_regularizer='l2',\n",
    "                       activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(128,\n",
    "#                        kernel_regularizer='l2',\n",
    "                       activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(32,\n",
    "#                        kernel_regularizer='l2',\n",
    "                       activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "nn_model.compile(optimizer='adam', #rmsprop\n",
    "              loss=\"mae\",\n",
    "              metrics=[\"mse\"],)\n",
    "\n",
    "nn_model.fit(X_train,\n",
    "             y_train,\n",
    "             epochs=200,\n",
    "             validation_data=(X_val, y_val),\n",
    "             verbose=1,\n",
    "             callbacks=my_callbacks,\n",
    "             batch_size=40\n",
    "            )\n",
    "\n",
    "nn_model.load_weights(\"models/best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step\n",
      "Mean Absolute Error: 8.035\n",
      "Mean Squared Error: 174.597\n",
      "Root Mean Squared Error: 13.214\n",
      "Mean absolute percentage error: 142.506\n",
      "Scaled Mean absolute percentage error: 35.362\n",
      "r2_score: 0.854\n"
     ]
    }
   ],
   "source": [
    "# best 0.87\n",
    "metrics_eval(y_val, nn_model.predict(X_val).flatten());"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# XGBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": "GridSearchCV(cv=3,\n             estimator=XGBRegressor(base_score=None, booster='gbtree',\n                                    callbacks=None, colsample_bylevel=None,\n                                    colsample_bynode=None,\n                                    colsample_bytree=None,\n                                    early_stopping_rounds=None,\n                                    enable_categorical=False, eval_metric=None,\n                                    feature_types=None, gamma=None, gpu_id=None,\n                                    grow_policy=None, importance_type=None,\n                                    interaction_constraints=None,\n                                    learning_rate=No...\n                                    max_cat_to_onehot=None, max_delta_step=None,\n                                    max_depth=None, max_leaves=None,\n                                    min_child_weight=None, missing=nan,\n                                    monotone_constraints=None, n_estimators=100,\n                                    n_jobs=None, num_parallel_tree=None,\n                                    predictor=None, random_state=42, ...),\n             n_jobs=-1,\n             param_grid={'colsample_bytree': [0.8], 'gamma': [0.5],\n                         'learning_rate': [0.3], 'max_depth': [6],\n                         'n_estimators': [300], 'subsample': [0.8]},\n             verbose=2)",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n             estimator=XGBRegressor(base_score=None, booster=&#x27;gbtree&#x27;,\n                                    callbacks=None, colsample_bylevel=None,\n                                    colsample_bynode=None,\n                                    colsample_bytree=None,\n                                    early_stopping_rounds=None,\n                                    enable_categorical=False, eval_metric=None,\n                                    feature_types=None, gamma=None, gpu_id=None,\n                                    grow_policy=None, importance_type=None,\n                                    interaction_constraints=None,\n                                    learning_rate=No...\n                                    max_cat_to_onehot=None, max_delta_step=None,\n                                    max_depth=None, max_leaves=None,\n                                    min_child_weight=None, missing=nan,\n                                    monotone_constraints=None, n_estimators=100,\n                                    n_jobs=None, num_parallel_tree=None,\n                                    predictor=None, random_state=42, ...),\n             n_jobs=-1,\n             param_grid={&#x27;colsample_bytree&#x27;: [0.8], &#x27;gamma&#x27;: [0.5],\n                         &#x27;learning_rate&#x27;: [0.3], &#x27;max_depth&#x27;: [6],\n                         &#x27;n_estimators&#x27;: [300], &#x27;subsample&#x27;: [0.8]},\n             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n             estimator=XGBRegressor(base_score=None, booster=&#x27;gbtree&#x27;,\n                                    callbacks=None, colsample_bylevel=None,\n                                    colsample_bynode=None,\n                                    colsample_bytree=None,\n                                    early_stopping_rounds=None,\n                                    enable_categorical=False, eval_metric=None,\n                                    feature_types=None, gamma=None, gpu_id=None,\n                                    grow_policy=None, importance_type=None,\n                                    interaction_constraints=None,\n                                    learning_rate=No...\n                                    max_cat_to_onehot=None, max_delta_step=None,\n                                    max_depth=None, max_leaves=None,\n                                    min_child_weight=None, missing=nan,\n                                    monotone_constraints=None, n_estimators=100,\n                                    n_jobs=None, num_parallel_tree=None,\n                                    predictor=None, random_state=42, ...),\n             n_jobs=-1,\n             param_grid={&#x27;colsample_bytree&#x27;: [0.8], &#x27;gamma&#x27;: [0.5],\n                         &#x27;learning_rate&#x27;: [0.3], &#x27;max_depth&#x27;: [6],\n                         &#x27;n_estimators&#x27;: [300], &#x27;subsample&#x27;: [0.8]},\n             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=42, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=42, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\",\n",
    "#                              eval_metric=\"mae\",\n",
    "                             booster=\"gbtree\",\n",
    "                             verbosity=1,\n",
    "                             random_state=42) # squarederror, reg:pseudohubererror\n",
    "\n",
    "params = {\n",
    "    \"colsample_bytree\": [0.8],\n",
    "    \"gamma\": [0.5],\n",
    "    \"learning_rate\": [0.3], # default 0.1 \n",
    "    \"max_depth\": [6], # default 3\n",
    "    \"n_estimators\": [300], # default 100\n",
    "    \"subsample\": [0.8]\n",
    "}\n",
    "\n",
    "search_xgb = GridSearchCV(xgb_model, \n",
    "                    param_grid=params,\n",
    "                    cv=3,\n",
    "                    verbose=2,\n",
    "                  n_jobs=-1)\n",
    "search_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 5.488\n",
      "Mean Squared Error: 84.24\n",
      "Root Mean Squared Error: 9.178\n",
      "Mean absolute percentage error: 90.323\n",
      "Scaled Mean absolute percentage error: 33.825\n",
      "r2_score: 0.93\n"
     ]
    }
   ],
   "source": [
    "metrics_eval(y_val, search_xgb.best_estimator_.predict(X_val));"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat([test_df, formula_test_df], axis=1).drop(\"material\",axis=1)\n",
    "\n",
    "std_test = pd.DataFrame(my_scaler.transform(test),\n",
    "                        columns=test_df.columns.tolist() + formula_test_df.drop(\"material\",axis=1).columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save xgb prediction\n",
    "pd.DataFrame(search_xgb.best_estimator_.predict(std_test)).to_csv(\"outputs/answer.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}